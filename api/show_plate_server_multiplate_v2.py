"""
Author: chenlei
Date: 2024-01-20
Description: è‚¡ç¥¨å¤šæ¿å—ä»ªè¡¨ç›˜æœåŠ¡ - åŸºäºæ–°æ¡†æ¶é‡æ„ç‰ˆæœ¬
åŠŸèƒ½: æä¾›å¤šæ¿å—è‚¡ç¥¨æ•°æ®å±•ç¤ºã€å®æ—¶æ¶¨å¹…åˆ†æã€æ¶¨åœç›‘æ§ç­‰åŠŸèƒ½
"""

import time
import pandas as pd
import numpy as np
import json
import pickle
import datetime
import plotly
import plotly.graph_objects as go
import os
import sys
import queue
from flask import request, Response, jsonify
from flask_cors import CORS

# å¯¼å…¥æ–°æ¡†æ¶åŸºç±»
from base_server import BaseStockServer

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥è‚¡ç¥¨æ•°æ®å’Œç­–ç•¥å‡½æ•°
from utils.common import get_trade_date_by_offset
from stock_data.stock.stock_daily import StockDailyData
from stock_data.stock_minute import StockMinuteData
from strategy.strategy001.æ¿å—ä¿¡æ¯æ˜¾ç¤º import plot_stock_line_charts

class MultiPlateStockServer(BaseStockServer):
    """å¤šæ¿å—è‚¡ç¥¨æœåŠ¡å™¨ - ç»§æ‰¿è‡ªBaseStockServer"""
    
    def __init__(self, port=5008):
        super().__init__(port=port, service_name="å¤šæ¿å—è‚¡ç¥¨ä»ªè¡¨ç›˜")
        
        # æœåŠ¡ç‰¹å®šçš„é…ç½®
        self.data_cache = DataCache()
        self.dynamic_titles = {
            "table2": "è‚¡ç¥¨æ•°æ®è¡¨",
            "table21": "è‚¡ç¥¨æ•°æ®è¡¨", 
            "table22": "è‚¡ç¥¨æ•°æ®è¡¨", 
            "table23": "è‚¡ç¥¨æ•°æ®è¡¨", 
            "table24": "è‚¡ç¥¨æ•°æ®è¡¨",
            "table12": "èˆªè¿æ¦‚å¿µ"
        }
        self.selected_sector = "èˆªè¿æ¦‚å¿µ"
        self.latest_update = {
            "sector": "èˆªè¿æ¦‚å¿µ",
            "componentId": "chart2", 
            "timestamp": time.time()
        }
        self.sse_clients = []
        self.message_queue = queue.Queue()
        
        # åˆå§‹åŒ–è‚¡ç¥¨æ•°æ®
        self._init_stock_data()
        
        # è¯»å–è‡ªå®šä¹‰æ¿å—
        self.my_plate_list = self._get_my_plate()

    def _init_stock_data(self):
        """åˆå§‹åŒ–è‚¡ç¥¨æ•°æ®"""
        try:
            self.stock_daily_ins = StockDailyData()
            today = datetime.datetime.now().strftime("%Y%m%d")
            today = '20250530'  # for test
            yesterday = get_trade_date_by_offset(today, 1)
            self.stock_daily_df = self.stock_daily_ins.get_daily_data(
                start_date=yesterday, end_date=yesterday
            )
            self.logger.info(f"è‚¡ç¥¨æ•°æ®åˆå§‹åŒ–å®Œæˆï¼Œè·å– {len(self.stock_daily_df)} æ¡è®°å½•")
        except Exception as e:
            self.logger.error(f"è‚¡ç¥¨æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")
            self.stock_daily_df = pd.DataFrame()

    def _get_my_plate(self, path=r'api\è‡ªå®šä¹‰ä¼˜å…ˆæ¿å—.txt'):
        """è¯»å–è‡ªå®šä¹‰ä¼˜å…ˆæ¿å—"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                my_plate = f.read().strip()
                my_plate = my_plate.replace('\n', '').replace('\r', '')
                if my_plate:
                    return my_plate.split(',')
                else:
                    return []
        except Exception as e:
            self.logger.warning(f"è¯»å–è‡ªå®šä¹‰ä¼˜å…ˆæ¿å—å¤±è´¥: {e}")
            return []

    def get_dashboard_config(self):
        """è·å–ä»ªè¡¨ç›˜é…ç½®"""
        # åˆå§‹åŒ–åŠ¨æ€æ ‡é¢˜
        if not self.dynamic_titles or all(title == "è‚¡ç¥¨æ•°æ®è¡¨" for title in self.dynamic_titles.values() if 'table' in str(title)):
            self._update_dynamic_titles()
            self.logger.info("åˆå§‹åŒ–åŠ¨æ€æ ‡é¢˜")
        else:
            self.logger.info(f"ä½¿ç”¨ç°æœ‰åŠ¨æ€æ ‡é¢˜: {self.dynamic_titles}")
        
        return {
            "layout": {
                "rows": 6,
                "cols": 5,
                "components": [
                    {
                        "id": "chart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/sector-line-chart_change",
                        "title": "æ¿å—æ¶¨å¹…æŠ˜çº¿å›¾",
                        "position": {"row": 0, "col": 0, "rowSpan": 1, "colSpan": 1}
                    },
                    {
                        "id": "chart_speed",
                        "type": "chart",
                        "dataSource": "/api/table-data/sector_speed_chart",
                        "title": "æ¿å—æ¶¨é€Ÿç´¯åŠ æŠ˜çº¿å›¾",
                        "position": {"row": 5, "col": 0, "rowSpan": 1, "colSpan": 3}
                    },
                    {
                        "id": "chart2",
                        "type": "chart", 
                        "dataSource": "/api/chart-data/sector-line-chart_uplimit",
                        "title": "æ¿å—è¿‘ä¼¼æ¶¨åœæŠ˜çº¿å›¾",
                        "position": {"row": 2, "col": 0, "rowSpan": 1, "colSpan": 3}
                    },
                    {
                        "id": "chart3",
                        "type": "chart", 
                        "dataSource": "/api/chart-data/sector-line-chart_uprate",
                        "title": "æ¿å—çº¢ç›˜ç‡æŠ˜çº¿å›¾",
                        "position": {"row": 0, "col": 2, "rowSpan": 1, "colSpan": 1}
                    },
                    {
                        "id": "chart4",
                        "type": "chart", 
                        "dataSource": "/api/chart-data/sector-line-chart_uprate5",
                        "title": "æ¿å—uprate5æŠ˜çº¿å›¾",
                        "position": {"row": 0, "col": 3, "rowSpan": 1, "colSpan": 1}
                    },
                    {
                        "id": "table1",
                        "type": "table",
                        "dataSource": "/api/table-data/plate_info",
                        "title": "æ¿å—æ¦‚è¦æ•°æ®è¡¨",
                        "position": {"row": 1, "col": 0, "rowSpan": 1, "colSpan": 3},
                        "height": "800px"
                    },
                    {
                        "id": "table12",
                        "type": "table",
                        "dataSource": "/api/table-data/stocks",
                        "title": self.dynamic_titles.get("table12", "è‚¡ç¥¨æ•°æ®è¡¨"),
                        "position": {"row": 1, "col": 3, "rowSpan": 1, "colSpan": 1},
                        "height": "800px"
                    },
                    {
                        "id": "upLimitTable",
                        "type": "table",
                        "dataSource": "/api/table-data/up_limit",
                        "title": "æ¶¨åœæ•°æ®è¡¨",
                        "position": {"row": 0, "col": 4, "rowSpan": 5, "colSpan": 1},
                        "height": "1300px"
                    }
                ]
            }
        }

    def get_data_sources(self):
        """è·å–æ•°æ®æºé…ç½®"""
        return {
            "/api/chart-data/sector-line-chart_change": {
                "handler": "get_sector_chart_data_change",
                "description": "æ¿å—æ¶¨å¹…æŠ˜çº¿å›¾æ•°æ®",
                "cache_ttl": 30
            },
            "/api/chart-data/sector-line-chart_uplimit": {
                "handler": "get_sector_chart_data_uplimit", 
                "description": "æ¿å—è¿‘ä¼¼æ¶¨åœæŠ˜çº¿å›¾æ•°æ®",
                "cache_ttl": 30
            },
            "/api/chart-data/sector-line-chart_uprate": {
                "handler": "get_sector_chart_data_uprate",
                "description": "æ¿å—çº¢ç›˜ç‡æŠ˜çº¿å›¾æ•°æ®", 
                "cache_ttl": 30
            },
            "/api/chart-data/sector-line-chart_uprate5": {
                "handler": "get_sector_chart_data_uprate5",
                "description": "æ¿å—uprate5æŠ˜çº¿å›¾æ•°æ®",
                "cache_ttl": 30
            },
            "/api/table-data/sector_speed_chart": {
                "handler": "get_sector_speed_chart",
                "description": "æ¿å—æ¶¨é€Ÿç´¯åŠ å›¾è¡¨æ•°æ®",
                "cache_ttl": 30
            },
            "/api/table-data/plate_info": {
                "handler": "get_plate_info_table_data",
                "description": "æ¿å—æ¦‚è¦æ•°æ®è¡¨",
                "cache_ttl": 60
            },
            "/api/table-data/stocks": {
                "handler": "get_stocks_table_data", 
                "description": "è‚¡ç¥¨æ•°æ®è¡¨",
                "cache_ttl": 30
            },
            "/api/table-data/up_limit": {
                "handler": "get_up_limit_table_data",
                "description": "æ¶¨åœæ•°æ®è¡¨",
                "cache_ttl": 60
            }
        }

    def register_custom_routes(self):
        """æ³¨å†Œè‡ªå®šä¹‰è·¯ç”± - åŸºç±»ä¼šè‡ªåŠ¨è°ƒç”¨handlerï¼Œæ— éœ€æ‰‹å·¥æ³¨å†Œ"""
        # ç”±äºåŸºç±»ç°åœ¨æ”¯æŒè‡ªåŠ¨handlerè°ƒç”¨ï¼Œå¤§éƒ¨åˆ†è·¯ç”±æ— éœ€æ‰‹å·¥æ³¨å†Œ
        # åªä¿ç•™ç‰¹æ®Šçš„è·¯ç”±éœ€æ±‚
        pass
        
        # æ³¨å†ŒSSEå’Œæ›´æ–°ç›¸å…³è·¯ç”±
        self.app.add_url_rule('/api/dashboard/update',
                             'update_dashboard',
                             self.update_dashboard, methods=['POST'])
        
        self.app.add_url_rule('/api/dashboard/updates',
                             'dashboard_updates',
                             self.dashboard_updates, methods=['GET'])
        
        self.app.add_url_rule('/api/dashboard/notify-update',
                             'notify_update', 
                             self.notify_update, methods=['POST'])
        
        self.app.add_url_rule('/api/debug/dynamic-titles',
                             'get_dynamic_titles_debug',
                             self.get_dynamic_titles_debug, methods=['GET'])

    # ===== æ•°æ®å¤„ç†æ–¹æ³• =====
    
    def get_sector_chart_data_change(self):
        """è¿”å›æ¿å—æ¶¨å¹…æŠ˜çº¿å›¾æ•°æ®"""
        try:
            sector_names = self._get_dynamic_titles_list()
            sector_df = pd.read_csv('strategy\\showhtml\\server\\good_plate_df.csv')
            
            sector_df['æ—¶é—´'] = pd.to_datetime(sector_df['æ—¶é—´'])
            sector_df = sector_df[sector_df['æ—¶é—´'].dt.date == sector_df['æ—¶é—´'].dt.date.max()]
            
            chart_data = []
            latest_time = sector_df['æ—¶é—´'].max()
            temp_df = sector_df[sector_df['æ—¶é—´'] == latest_time]
            
            sector_names_speed = temp_df.sort_values(by='æ¿å—5åˆ†æ¶¨é€Ÿ', ascending=False).head(10)['æ¿å—å'].tolist()
            sector_names_change = temp_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(20)['æ¿å—å'].tolist()
            sector_names = list(set(sector_names + sector_names_speed + sector_names_change))
            
            for sector_name in sector_names:
                sector_data = sector_df[sector_df['æ¿å—å'] == sector_name]
                if not sector_data.empty:
                    sector_data = sector_data.sort_values(by='æ—¶é—´')
                    chart_data.append({
                        "name": f'{sector_name}æ¶¨å¹…',
                        "x": sector_data['æ—¶é—´'].dt.strftime('%Y-%m-%d %H:%M').tolist(),
                        "y": sector_data['æ¿å—æ¶¨å¹…'].tolist()
                    })
            
            return jsonify({
                "chartType": "line",
                "data": chart_data,
                "layout": {
                    "title": "æ¿å—æ¶¨å¹…",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "æ¶¨å¹…(%)"},
                    "legend": {"title": "æ¿å—åç§°"}
                }
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—æ¶¨å¹…æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_sector_chart_data_uplimit(self):
        """è¿”å›æ¿å—è¿‘ä¼¼æ¶¨åœæŠ˜çº¿å›¾æ•°æ®"""
        try:
            sector_names = self._get_dynamic_titles_list()
            sector_df = pd.read_csv('strategy\\showhtml\\server\\good_plate_df.csv')
            
            sector_df['æ—¶é—´'] = pd.to_datetime(sector_df['æ—¶é—´'])
            sector_df = sector_df[sector_df['æ—¶é—´'].dt.date == sector_df['æ—¶é—´'].dt.date.max()]
            
            # æ·»åŠ è¿‘ä¼¼æ¶¨åœæ•°åˆ—
            sector_df['è¿‘ä¼¼æ¶¨åœæ•°'] = sector_df['æ¶¨å¹…åˆ†å¸ƒ'].apply(
                lambda x: int(x.split('-')[-1]) if '-' in x else 0
            )
            
            chart_data = []
            latest_time = sector_df['æ—¶é—´'].max()
            temp_df = sector_df[sector_df['æ—¶é—´'] == latest_time]
            
            sector_names_speed = temp_df.sort_values(by='æ¿å—5åˆ†æ¶¨é€Ÿ', ascending=False).head(3)['æ¿å—å'].tolist()
            sector_names_change = temp_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(220)['æ¿å—å'].tolist()
            sector_names = list(set(sector_names + sector_names_speed + sector_names_change))
            
            for sector_name in sector_names:
                sector_data = sector_df[sector_df['æ¿å—å'] == sector_name]
                if not sector_data.empty:
                    sector_data = sector_data.sort_values(by='æ—¶é—´')
                    chart_data.append({
                        "name": f'{sector_name}è¿‘ä¼¼æ¶¨åœæ•°',
                        "x": sector_data['æ—¶é—´'].dt.strftime('%Y-%m-%d %H:%M').tolist(),
                        "y": sector_data['è¿‘ä¼¼æ¶¨åœæ•°'].tolist()
                    })
            
            return jsonify({
                "chartType": "line",
                "data": chart_data,
                "layout": {
                    "title": "æ¿å—è¿‘ä¼¼æ¶¨åœæ•°",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "è¿‘ä¼¼æ¶¨åœæ•°"},
                    "legend": {"title": "æ¿å—åç§°"}
                }
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—æ¶¨åœæ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_sector_chart_data_uprate(self):
        """è¿”å›æ¿å—çº¢ç›˜ç‡æŠ˜çº¿å›¾æ•°æ®"""
        try:
            sector_names = self._get_dynamic_titles_list()
            sector_df = pd.read_csv('strategy\\showhtml\\server\\good_plate_df.csv')
            
            sector_df['æ—¶é—´'] = pd.to_datetime(sector_df['æ—¶é—´'])
            sector_df = sector_df[sector_df['æ—¶é—´'].dt.date == sector_df['æ—¶é—´'].dt.date.max()]
            sector_df['uprate'] = sector_df['æ¶¨å¹…åˆ†å¸ƒ'].apply(lambda x: self._calculate_tail_ratio(x, n=6))
            
            chart_data = []
            latest_time = sector_df['æ—¶é—´'].max()
            temp_df = sector_df[sector_df['æ—¶é—´'] == latest_time]
            
            sector_names_speed = temp_df.sort_values(by='æ¿å—5åˆ†æ¶¨é€Ÿ', ascending=False).head(3)['æ¿å—å'].tolist()
            sector_names_change = temp_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(3)['æ¿å—å'].tolist()
            sector_names = list(set(sector_names + sector_names_speed + sector_names_change))
            
            for sector_name in sector_names:
                sector_data = sector_df[sector_df['æ¿å—å'] == sector_name]
                if not sector_data.empty:
                    sector_data = sector_data.sort_values(by='æ—¶é—´')
                    chart_data.append({
                        "name": f'{sector_name}çº¢ç›˜ç‡',
                        "x": sector_data['æ—¶é—´'].dt.strftime('%Y-%m-%d %H:%M').tolist(),
                        "y": sector_data['uprate'].tolist()
                    })
            
            return jsonify({
                "chartType": "line",
                "data": chart_data,
                "layout": {
                    "title": "æ¿å—çº¢ç›˜ç‡",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "çº¢ç›˜ç‡"},
                    "legend": {"title": "æ¿å—åç§°"}
                }
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—çº¢ç›˜ç‡æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_sector_chart_data_uprate5(self):
        """è¿”å›æ¿å—uprate5æŠ˜çº¿å›¾æ•°æ®"""
        try:
            sector_names = self._get_dynamic_titles_list()
            sector_df = pd.read_csv('strategy\\showhtml\\server\\good_plate_df.csv')
            
            sector_df['æ—¶é—´'] = pd.to_datetime(sector_df['æ—¶é—´'])
            sector_df = sector_df[sector_df['æ—¶é—´'].dt.date == sector_df['æ—¶é—´'].dt.date.max()]
            sector_df['uprate5'] = sector_df['æ¶¨å¹…åˆ†å¸ƒ'].apply(lambda x: self._calculate_tail_ratio(x, n=3))
            
            chart_data = []
            latest_time = sector_df['æ—¶é—´'].max()
            temp_df = sector_df[sector_df['æ—¶é—´'] == latest_time]
            
            sector_names_speed = temp_df.sort_values(by='æ¿å—5åˆ†æ¶¨é€Ÿ', ascending=False).head(3)['æ¿å—å'].tolist()
            sector_names_change = temp_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(3)['æ¿å—å'].tolist()
            sector_names = list(set(sector_names + sector_names_speed + sector_names_change))
            
            for sector_name in sector_names:
                sector_data = sector_df[sector_df['æ¿å—å'] == sector_name]
                if not sector_data.empty:
                    sector_data = sector_data.sort_values(by='æ—¶é—´')
                    chart_data.append({
                        "name": f'{sector_name}çº¢ç›˜ç‡',
                        "x": sector_data['æ—¶é—´'].dt.strftime('%Y-%m-%d %H:%M').tolist(),
                        "y": sector_data['uprate5'].tolist()
                    })
            
            return jsonify({
                "chartType": "line",
                "data": chart_data,
                "layout": {
                    "title": "æ¿å—uprate5",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "uprate5"},
                    "legend": {"title": "æ¿å—åç§°"}
                }
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—uprate5æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_sector_speed_chart(self):
        """è¿”å›æ¿å—æ¶¨é€Ÿç´¯åŠ å›¾è¡¨æ•°æ®"""
        try:
            top_sectors = self._get_top_sectors(120)
            
            stock_df = self.data_cache.load_data('stock_df')
            if stock_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": "è‚¡ç¥¨æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥"
                })
            
            stock_minute_df = self.data_cache.load_data('stock_minute_df')
            if stock_minute_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": "åˆ†é’Ÿæ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥"
                })
            
            # æ•°æ®æ¸…ç†å’Œé¢„å¤„ç†
            stock_df = stock_df.replace([np.inf, -np.inf], 0).fillna(0)
            stock_minute_df = stock_minute_df.replace([np.inf, -np.inf], 0).fillna(0)
            
            stock_df['Sector'] = stock_df['Sector'].astype(str)
            stock_df['id'] = stock_df['id'].astype(int)
            stock_df['change'] = stock_df['change'].astype(float)
            stock_df['time'] = pd.to_datetime(stock_df['time'])
            
            latest_time = stock_df['time'].max()
            stock_df = stock_df[stock_df['time'] == latest_time]
            
            affinity_df = self.data_cache.load_data('affinity_df')
            if affinity_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": "æ¿å—å…³è”æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥"
                })
            
            chart_data = []
            
            for sector_name in top_sectors:
                # æ¨¡ç³ŠåŒ¹é…æ¿å—
                sector_affinity_df = affinity_df[
                    affinity_df['æ¿å—'].str.contains(sector_name, na=False, case=False) |
                    affinity_df['æ¿å—'].apply(lambda x: sector_name in str(x) if pd.notna(x) else False)
                ]
                
                if sector_affinity_df.empty:
                    continue
                
                stock_ids = list(set(sector_affinity_df['è‚¡ç¥¨id'].tolist()))
                stock_count = len(stock_ids)
                
                # è¿‡æ»¤è‚¡ç¥¨ID
                stock_ids = [id for id in stock_ids if id < 680000 and (id < 400000 or id > 600000)]
                filtered_count = len(stock_ids)
                
                stock_minute_df_temp = stock_minute_df[stock_minute_df['id'].isin(stock_ids)]
                stock_minute_df_temp = stock_minute_df_temp[stock_minute_df_temp['change'] > 2]
                
                if stock_minute_df_temp.empty:
                    continue
                
                # æŒ‰æ—¶é—´ç»„èšåˆ
                stock_minute_df_temp = stock_minute_df_temp.groupby('time').agg({
                    'speed_change_1min': 'mean',
                    'id': 'count'
                }).reset_index()
                
                stock_minute_df_temp = stock_minute_df_temp.rename(columns={'id': 'stock_count'})
                stock_minute_df_temp = stock_minute_df_temp.sort_values('time')
                
                stock_minute_df_temp['speed_change_1min_rate'] = (
                    stock_minute_df_temp['speed_change_1min'] * 
                    stock_minute_df_temp['stock_count'] / filtered_count
                )
                stock_minute_df_temp['speed_change_1min_cumsum'] = (
                    stock_minute_df_temp['speed_change_1min_rate'].cumsum()
                )
                
                stock_minute_df_temp['time'] = pd.to_datetime(stock_minute_df_temp['time'])
                
                chart_data.append({
                    "name": f'{sector_name}æ¶¨é€Ÿå˜åŒ–ç´¯è®¡',
                    "x": stock_minute_df_temp['time'].dt.strftime('%Y-%m-%d %H:%M').tolist(),
                    "y": stock_minute_df_temp['speed_change_1min_cumsum'].tolist()
                })
            
            return jsonify({
                "chartType": "line",
                "data": chart_data,
                "layout": {
                    "title": "æ¿å—æ¶¨é€Ÿå˜åŒ–ç´¯è®¡",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "ç´¯è®¡æ¶¨é€Ÿ"},
                    "legend": {"title": "æ¿å—åç§°"}
                }
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—æ¶¨é€Ÿæ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_plate_info_table_data(self):
        """è¿”å›æ¿å—æ¦‚è¦æ•°æ®è¡¨"""
        try:
            start_time = time.time()
            sector_name = request.args.get('sectors', 'èˆªè¿æ¦‚å¿µ')
            
            plate_df = self.data_cache.load_data('plate_df')
            if plate_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": "æ¿å—æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥"
                })
            
            # æ•°æ®å¤„ç†
            plate_df['æ—¶é—´'] = pd.to_datetime(plate_df['æ—¶é—´'])
            latest_time = plate_df['æ—¶é—´'].max()
            plate_df = plate_df[plate_df['æ—¶é—´'] == latest_time]
            
            # è®¡ç®—å¤§ç›˜æ¶¨é€Ÿåˆ†å¸ƒ
            speed_bins = [-10, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 10]
            speed_counts = []
            for i in range(len(speed_bins)-1):
                count = len(plate_df[
                    (plate_df['æ¿å—5åˆ†æ¶¨é€Ÿ'] >= speed_bins[i]) & 
                    (plate_df['æ¿å—5åˆ†æ¶¨é€Ÿ'] < speed_bins[i+1])
                ])
                speed_counts.append(str(count))
            market_speed_distribution = "-".join(speed_counts)
            plate_df['å¤§ç›˜æ¶¨é€Ÿåˆ†å¸ƒ'] = market_speed_distribution
            
            plate_df['æ¿å—å'] = plate_df['æ¿å—å'].astype(str)
            
            # è·å–æ’åå‰15çš„æ¿å—
            top_by_change = plate_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(15)['æ¿å—å'].tolist()
            top_by_turnover = plate_df.sort_values(by='å¼ºåŠ¿åˆ†æ—¶æ¢æ‰‹å æ¯”', ascending=False).head(15)['æ¿å—å'].tolist()
            top_plates_list = list(set(top_by_change + top_by_turnover))
            
            if sector_name not in top_plates_list:
                top_plates_list.append(sector_name)
            
            plate_df = plate_df[plate_df['æ¿å—å'].isin(top_plates_list)]
            plate_df = plate_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False)
            plate_df = plate_df.drop_duplicates(subset=['æ¿å—å']).reset_index(drop=True)
            
            # å®šä¹‰è¡¨æ ¼åˆ—
            columns = [
                {"field": "æ—¶é—´", "header": "æ—¶é—´"},
                {"field": "æ¿å—å", "header": "æ¿å—å"},
                {"field": "æ¿å—æ¶¨å¹…", "header": "æ¿å—æ¶¨å¹…", "backgroundColor": "redGreen"},
                {"field": "æ¿å—æ˜¨æ—¥æ¶¨å¹…", "header": "æ¿å—æ˜¨æ—¥æ¶¨å¹…", "backgroundColor": "redGreen"},
                {"field": "å¼ºåŠ¿åˆ†æ—¶æ¢æ‰‹å æ¯”", "header": "å¼ºåŠ¿åˆ†æ—¶æ¢æ‰‹å æ¯”", "backgroundColor": "redGreen"},
                {"field": "æ¿å—5åˆ†æ¶¨é€Ÿ", "header": "æ¿å—5åˆ†æ¶¨é€Ÿ", "backgroundColor": "redGreen"},
                {"field": "æ¿å—é‡æ¯”", "header": "æ¿å—é‡æ¯”", "backgroundColor": "redGreen"},
                {"field": "æ¶¨é€Ÿåˆ†å¸ƒ", "header": "æ¶¨é€Ÿåˆ†å¸ƒ"},
                {"field": "æ¶¨å¹…åˆ†å¸ƒ", "header": "æ¶¨å¹…åˆ†å¸ƒ"},
                {"field": "æ¶¨åœæ¢¯åº¦", "header": "æ¶¨åœæ¢¯åº¦"},
                {"field": "æ¶¨é€Ÿæ’å", "header": "æ¶¨é€Ÿæ’å"},
                {"field": "æ¶¨å¹…æ’å", "header": "æ¶¨å¹…æ’å"},
                {"field": "å¤§ç›˜é‡æ¯”", "header": "å¤§ç›˜é‡æ¯”"},
                {"field": "å¤§ç›˜æ¶¨é€Ÿåˆ†å¸ƒ", "header": "å¤§ç›˜æ¶¨é€Ÿåˆ†å¸ƒ"},
            ]
            
            valid_columns = [col for col in columns if col["field"] in plate_df.columns]
            
            rows = []
            for _, row_data in plate_df.iterrows():
                row = {}
                for col in valid_columns:
                    field = col["field"]
                    value = row_data[field]
                    
                    if isinstance(value, (float, np.float64, np.float32)):
                        value = round(value, 2)
                    
                    row[field] = value
                
                rows.append(row)
            
            return jsonify({
                "columns": valid_columns,
                "rows": rows
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—ä¿¡æ¯å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_stocks_table_data(self):
        """è¿”å›è‚¡ç¥¨æ•°æ®è¡¨"""
        try:
            sector_name = request.args.get('sector_name') or request.args.get('sectors', 'èˆªè¿æ¦‚å¿µ')
            component_id = request.args.get('componentId', 'table2')
            
            self.logger.info(f"APIè°ƒç”¨: componentId={component_id}, ä¼ å…¥çš„sector_name={sector_name}")
            
            # å¯¹äºtable12ï¼Œä¼˜å…ˆä½¿ç”¨åŠ¨æ€æ ‡é¢˜
            if component_id == 'table12':
                sector_name = self.dynamic_titles.get('table12', sector_name)
                self.logger.info(f"table12 ä½¿ç”¨åŠ¨æ€æ ‡é¢˜ä¸­çš„æ¿å—: {sector_name}")
            
            # æ ¹æ®ç»„ä»¶IDè·å–å¯¹åº”æ¿å—
            if component_id in ['table2', 'table21', 'table22', 'table23', 'table24']:
                try:
                    top_sectors = self._get_top_sectors()
                    sector_map = {
                        'table2': 0, 'table21': 1, 'table22': 2, 'table23': 3, 'table24': 4
                    }
                    if component_id in sector_map and len(top_sectors) > sector_map[component_id]:
                        sector_name = top_sectors[sector_map[component_id]]
                        self.logger.info(f"ç»„ä»¶ {component_id} ä½¿ç”¨åŠ¨æ€æ¿å—: {sector_name}")
                except Exception as e:
                    self.logger.warning(f"è·å–åŠ¨æ€æ¿å—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¿å—: {e}")
            
            self.logger.info(f"æœ€ç»ˆä½¿ç”¨çš„æ¿å—åç§°: {sector_name}")
            
            # è¯»å–è‚¡ç¥¨æ•°æ®
            stock_df = self.data_cache.load_data('stock_df')
            if stock_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": "è‚¡ç¥¨æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥"
                })
            
            # æ•°æ®é¢„å¤„ç†
            stock_df['time'] = pd.to_datetime(stock_df['time'])
            latest_time = stock_df['time'].max()
            stock_df = stock_df[stock_df['time'] == latest_time]
            
            stock_df['Sector'] = stock_df['Sector'].astype(str)
            stock_df['id'] = stock_df['id'].astype(int)
            stock_df['change'] = stock_df['change'].astype(float)
            
            # è¯»å–æ¿å—å…³è”æ•°æ®
            affinity_df = pd.read_csv('strategy\\strategy001\\data\\æ¿å—å†…è‚¡ç¥¨åŒæ¶¨ç‡_é•¿å‘¨æœŸ.csv')
            
            # æ¨¡ç³ŠåŒ¹é…æ¿å—
            sector_affinity_df = affinity_df[
                affinity_df['æ¿å—'].str.contains(sector_name, na=False, case=False) |
                affinity_df['æ¿å—'].apply(lambda x: sector_name in str(x) if pd.notna(x) else False)
            ]
            
            if sector_affinity_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": f"æœªæ‰¾åˆ°åŒ…å« '{sector_name}' çš„æ¿å—è‚¡ç¥¨æ•°æ®"
                })
            
            matched_sectors = sector_affinity_df['æ¿å—'].unique()
            self.logger.info(f"åŒ¹é…åˆ°çš„æ¿å—: {matched_sectors}")
            
            stock_ids = sector_affinity_df['è‚¡ç¥¨id'].tolist()
            original_count = len(stock_ids)
            
            # è¿‡æ»¤è‚¡ç¥¨ID
            stock_ids = [id for id in stock_ids if id < 680000 and (id < 400000 or id > 600000)]
            self.logger.info(f"è¿‡æ»¤åå‰©ä½™ {len(stock_ids)} åªè‚¡ç¥¨ï¼ˆåŸå§‹: {original_count}ï¼‰")
            
            # è·å–è‚¡ç¥¨æ•°æ®
            sector_stock_df = stock_df[stock_df['id'].isin(stock_ids)]
            
            if sector_stock_df.empty:
                return jsonify({
                    "columns": [],
                    "rows": [],
                    "message": f"åœ¨å½“å‰æ•°æ®ä¸­æœªæ‰¾åˆ°æ¿å— '{sector_name}' çš„è‚¡ç¥¨"
                })
            
            # ç­›é€‰ä¼˜è´¨è‚¡ç¥¨
            stock1_list = sector_stock_df.sort_values(by='change', ascending=False).head(30)['id'].tolist()
            stock2_list = sector_stock_df[sector_stock_df['å¼€ç›˜æ¢æ‰‹ç‡'] > 0.08].sort_values(by='å¼€ç›˜æ¢æ‰‹ç‡', ascending=False)['id'].tolist()
            stock3_list = sector_stock_df[sector_stock_df['è¿‘10æ—¥å†…æ¶¨åœæ•°'] > 0]['id'].tolist()
            
            final_stock_ids = list(set(stock1_list) | set(stock2_list) | set(stock3_list))
            final_stock_df = sector_stock_df[sector_stock_df['id'].isin(final_stock_ids)]
            
            self.logger.info(f"æœ€ç»ˆç­›é€‰å‡º {len(final_stock_df)} åªä¼˜è´¨è‚¡ç¥¨")
            
            # åˆå¹¶åŒæ¶¨ç‡æ•°æ®
            final_stock_df = pd.merge(
                final_stock_df, 
                sector_affinity_df[['è‚¡ç¥¨id', 'åŒæ¶¨ç‡']], 
                left_on='id', right_on='è‚¡ç¥¨id', how='left'
            )
            
            # æ’åºå’Œå¡«å……
            final_stock_df = final_stock_df.sort_values(by='å¼€ç›˜æ¢æ‰‹ç‡', ascending=False)
            final_stock_df = final_stock_df.fillna(-1)
            final_stock_df = final_stock_df.sort_values(by='change', ascending=False)
            
            # å®šä¹‰è¡¨æ ¼åˆ—
            columns = [
                {"field": "id", "header": "è‚¡ç¥¨ID", "visible": False},
                {"field": "stock_name", "header": "è‚¡ç¥¨åç§°"},
                {"field": "æ˜¨æ—¥æ¶¨å¹…", "header": "æ˜¨æ¶¨å¹…", "backgroundColor": "redGreen"},
                {"field": "change", "header": "ä»Šæ¶¨å¹…(%)", "backgroundColor": "redGreen"},
                {"field": "ç«ä»·æ¶¨å¹…", "header": "ç«æ¶¨å¹…", "backgroundColor": "redGreen"},
                {"field": "å¼€ç›˜æ¢æ‰‹ç‡", "header": "ç«æ¢æ‰‹", "backgroundColor": "redGreen"},
                {"field": "volume_ratio", "header": "é‡æ¯”", "backgroundColor": "redGreen"},
                {"field": "è¿‘10æ—¥å†…æ¶¨åœæ•°", "header": "10æ—¥æ¶¨åœ", "backgroundColor": "redGreen"},
                {"field": "è¿æ¿æ•°", "header": "è¿æ¿æ•°", "backgroundColor": "redGreen", "visible": False},
                {"field": "å½“æ—¥æ¢æ‰‹ç‡", "header": "å½“æ—¥æ¢æ‰‹ç‡", "backgroundColor": "redGreen", "visible": False},
                {"field": "åŒæ¶¨ç‡", "header": "åŒæ¶¨ç‡", "backgroundColor": "redGreen", "visible": False},
            ]
            
            valid_columns = [col for col in columns if col["field"] in final_stock_df.columns]
            
            rows = []
            for _, row_data in final_stock_df.iterrows():
                row = {}
                for col in valid_columns:
                    field = col["field"]
                    value = row_data[field]
                    
                    if isinstance(value, (float, np.float64, np.float32)):
                        if np.isinf(value):
                            value = 999.99
                        else:
                            value = round(value, 2)
                    
                    row[field] = value
                
                rows.append(row)
            
            return jsonify({
                "columns": valid_columns,
                "rows": rows,
                "sector_name": sector_name,
                "total_stocks": len(rows)
            })
        
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    def get_up_limit_table_data(self):
        """è¿”å›æ¶¨åœæ•°æ®è¡¨"""
        try:
            up_limit_df = pd.read_csv(r'strategy\showhtml\server\up_limit_df.csv')
            
            columns = [
                {"field": "æ—¶é—´", "header": "æ—¶é—´"},
                {"field": "è‚¡ç¥¨ID", "header": "è‚¡ç¥¨ID", "visible": False},
                {"field": "è‚¡ç¥¨åç§°", "header": "è‚¡ç¥¨åç§°"},
                {"field": "æ¿å—1", "header": "æ¿å—1"},
                {"field": "æ¿å—2", "header": "æ¿å—2"},
                {"field": "æ¿å—3", "header": "æ¿å—3", "visible": False},
                {"field": "æ¿å—4", "header": "æ¿å—4", "visible": False},
                {"field": "æ¿å—5", "header": "æ¿å—5", "visible": False},
                {"field": "10æ—¥æ¶¨åœæ•°", "header": "10æ—¥æ¶¨åœæ•°"},
                {"field": "è¿æ¿æ•°", "header": "è¿æ¿æ•°", "visible": False},
            ]
            
            valid_columns = [col for col in columns if col["field"] in up_limit_df.columns]
            
            rows = []
            for _, row_data in up_limit_df.iterrows():
                row = {}
                for col in valid_columns:
                    field = col["field"]
                    value = row_data[field]
                    
                    if isinstance(value, (float, np.float64, np.float32)):
                        value = round(value, 2)
                    
                    row[field] = value
                
                rows.append(row)
            
            return jsonify({
                "columns": valid_columns,
                "rows": rows
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¶¨åœæ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    # ===== SSE å’Œæ›´æ–°ç›¸å…³æ–¹æ³• =====
    
    def update_dashboard(self):
        """æ¥æ”¶é¡µé¢æ›´æ–°è¯·æ±‚"""
        data = request.json
        self.logger.info(f"æ”¶åˆ°æ›´æ–°è¯·æ±‚: {data}")
        
        params = data.get('params', {})
        if isinstance(params, dict):
            sector_name = params.get('sectors', 'èˆªè¿æ¦‚å¿µ')
        else:
            sector_name = str(params) if params else 'èˆªè¿æ¦‚å¿µ'
        
        self.selected_sector = sector_name
        self.dynamic_titles['table12'] = sector_name
        
        self.latest_update = {
            "componentId": data.get('componentId', 'chart2'),
            "params": params,
            "timestamp": time.time(),
            "action": "config_update",
            "sector_name": sector_name
        }
        
        update_message = {
            "action": "reload_config",
            "sector_name": sector_name,
            "timestamp": time.time()
        }
        self._send_update_to_clients(update_message)
        
        return jsonify({
            "status": "success",
            "message": "Update request sent",
            "sector_name": sector_name,
            "updated_titles": self.dynamic_titles
        })

    def dashboard_updates(self):
        """SSEäº‹ä»¶æµ"""
        def event_stream():
            client_queue = queue.Queue()
            client_id = f"client_{len(self.sse_clients)}_{time.time()}"
            
            try:
                self.sse_clients.append(client_queue)
                self.logger.info(f"SSEå®¢æˆ·ç«¯è¿æ¥: {client_id}ï¼Œå½“å‰æ€»è¿æ¥æ•°: {len(self.sse_clients)}")
                
                connection_info = {
                    "type": "connection_established",
                    "client_id": client_id,
                    "timestamp": time.time(),
                    "server_status": "online"
                }
                yield f"data: {json.dumps(connection_info)}\n\n"
                yield f"data: {json.dumps(self.latest_update)}\n\n"
                
                while True:
                    try:
                        message = client_queue.get(block=True, timeout=10)
                        yield message
                    except queue.Empty:
                        heartbeat = {
                            "type": "heartbeat",
                            "client_id": client_id,
                            "timestamp": time.time(),
                            "server_time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "active_connections": len(self.sse_clients)
                        }
                        yield f"data: {json.dumps(heartbeat)}\n\n"
                        continue
                    except GeneratorExit:
                        self.logger.info(f"SSEå®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€: {client_id}")
                        break
                        
            except Exception as e:
                self.logger.error(f"SSEè¿æ¥å¼‚å¸¸ {client_id}: {e}")
            finally:
                if client_queue in self.sse_clients:
                    self.sse_clients.remove(client_queue)
                    self.logger.info(f"SSEå®¢æˆ·ç«¯æ¸…ç†: {client_id}ï¼Œå‰©ä½™è¿æ¥æ•°: {len(self.sse_clients)}")
        
        response = Response(event_stream(), mimetype="text/event-stream")
        response.headers.update({
            'Cache-Control': 'no-cache, no-store, must-revalidate',
            'Pragma': 'no-cache',
            'Expires': '0',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Cache-Control',
            'Keep-Alive': 'timeout=30, max=1000'
        })
        return response

    def notify_update(self):
        """æ¥æ”¶æ›´æ–°é€šçŸ¥å¹¶é€šè¿‡SSEå¹¿æ’­"""
        data = request.json
        
        try:
            top_sectors = self._update_dynamic_titles()
            self.logger.info(f"æ¶¨å¹…å‰5æ¿å—: {top_sectors}")
            self.logger.info(f"åŠ¨æ€æ ‡é¢˜å·²æ›´æ–°: {self.dynamic_titles}")
        except Exception as e:
            self.logger.error(f"notify_updateä¸­æ›´æ–°æ ‡é¢˜å¤±è´¥: {e}")
        
        update_message = {
            "action": "reload_config",
            "sector_name": self.selected_sector,
            "timestamp": time.time()
        }
        
        self._send_update_to_clients(update_message)
        return jsonify({
            "status": "success",
            "message": "æ›´æ–°é€šçŸ¥å·²å‘é€ï¼Œå‰ç«¯å°†é‡æ–°åŠ è½½é…ç½®"
        })

    def get_dynamic_titles_debug(self):
        """è°ƒè¯•ç«¯ç‚¹ï¼šè¿”å›å½“å‰çš„åŠ¨æ€æ ‡é¢˜çŠ¶æ€"""
        try:
            top_sectors = self._get_top_sectors()
        except:
            top_sectors = ["è·å–å¤±è´¥"]
        
        return jsonify({
            "dynamic_titles": self.dynamic_titles,
            "selected_sector": self.selected_sector,
            "latest_update": self.latest_update,
            "current_top_sectors": top_sectors,
            "timestamp": time.time()
        })

    # ===== è¾…åŠ©æ–¹æ³• =====
    
    def _send_update_to_clients(self, data):
        """å‘é€æ›´æ–°åˆ°æ‰€æœ‰SSEå®¢æˆ·ç«¯"""
        for client in list(self.sse_clients):
            try:
                client.put(f"data: {json.dumps(data)}\n\n")
            except:
                self.sse_clients.remove(client)

    def _get_dynamic_titles_list(self):
        """è·å–åŠ¨æ€æ ‡é¢˜åˆ—è¡¨"""
        return list(self.dynamic_titles.values())

    def _get_top_sectors(self, n=5):
        """è·å–æ¶¨å¹…å‰nçš„æ¿å—åç§°"""
        try:
            plate_df = pd.read_csv('strategy\\showhtml\\server\\good_plate_df.csv')
            plate_df['æ—¶é—´'] = pd.to_datetime(plate_df['æ—¶é—´'])
            latest_time = plate_df['æ—¶é—´'].max()
            plate_df = plate_df[plate_df['æ—¶é—´'] == latest_time]
            
            top_sectors = plate_df.sort_values(by='æ¿å—æ¶¨å¹…', ascending=False).head(n)
            top_sectors_list = top_sectors['æ¿å—å'].tolist()
            
            # åŠ å…¥è‡ªå®šä¹‰ä¼˜å…ˆæ¿å—
            top_sectors_list = self.my_plate_list + top_sectors_list
            return list(set(top_sectors_list))  # å»é‡
            
        except Exception as e:
            self.logger.error(f"è·å–æ¶¨å¹…å‰{n}æ¿å—å¤±è´¥: {e}")
            return ["èˆªè¿æ¦‚å¿µ", "å¯æ§æ ¸èšå˜", "å†›å·¥"]

    def _update_dynamic_titles(self):
        """æ›´æ–°åŠ¨æ€æ ‡é¢˜"""
        try:
            top_sectors = self._get_top_sectors()
            
            while len(top_sectors) < 5:
                top_sectors.append("é»˜è®¤æ¿å—")
            
            current_table12 = self.dynamic_titles.get("table12", self.selected_sector)
            
            self.dynamic_titles.update({
                "table2": f"{top_sectors[0]}",
                "table21": f"{top_sectors[1]}",
                "table22": f"{top_sectors[2]}",
                "table23": f"{top_sectors[3]}",
                "table24": f"{top_sectors[4]}",
            })
            
            self.dynamic_titles["table12"] = current_table12
            
            self.logger.info(f"åŠ¨æ€æ ‡é¢˜å·²æ›´æ–°: {self.dynamic_titles}")
            return top_sectors
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°åŠ¨æ€æ ‡é¢˜å¤±è´¥: {e}")
            return ["èˆªè¿æ¦‚å¿µ", "å¯æ§æ ¸èšå˜", "å†›å·¥"]

    def _calculate_tail_ratio(self, number_string, n):
        """è®¡ç®—å€’æ•°ånä¸ªæ•°çš„åˆè®¡ä¸æ€»åˆè®¡çš„æ¯”å€¼"""
        try:
            numbers = [float(x) for x in number_string.split('-')]
            total_sum = sum(numbers)
            tail_numbers = numbers[-n:] if n <= len(numbers) else numbers
            tail_sum = sum(tail_numbers)
            
            if total_sum == 0:
                return 0.0
            else:
                return round(tail_sum / total_sum, 2)
        except:
            return 0.0

    def _calculate_center_of_mass(self, number_string):
        """è®¡ç®—æ•°å­—ä¸²çš„é‡å¿ƒä½ç½®"""
        try:
            numbers = [float(x) for x in number_string.split('-')]
            weighted_sum = 0
            value_sum = 0
            
            for index, value in enumerate(numbers):
                position = index + 1
                weighted_sum += position * value
                value_sum += value
            
            if value_sum == 0:
                return 0
            
            return round(weighted_sum / value_sum, 2)
        except:
            return 0


# æ•°æ®ç¼“å­˜ç±» - ä¿æŒåŸæœ‰é€»è¾‘
class DataCache:
    def __init__(self):
        self.cache = {}
        self.timestamps = {}
        
    def get_file_path(self, file_key):
        """è·å–æ–‡ä»¶è·¯å¾„"""
        paths = {
            'stock_df': 'strategy\\showhtml\\server\\stock_df.csv',
            'affinity_df': 'strategy\\strategy001\\data\\æ¿å—å†…è‚¡ç¥¨åŒæ¶¨ç‡_é•¿å‘¨æœŸ.csv',
            'plate_df': 'strategy\\showhtml\\server\\good_plate_df.csv',
            'stock_minute_df': 'strategy\\showhtml\\server\\stock_minute_df.csv',
        }
        return paths.get(file_key)
        
    def get_file_timestamp(self, file_path):
        """è·å–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´æˆ³"""
        try:
            return os.path.getmtime(file_path)
        except OSError:
            return 0
            
    def should_reload(self, file_key):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½æ–‡ä»¶"""
        file_path = self.get_file_path(file_key)
        if not file_path or not os.path.exists(file_path):
            return False
            
        current_timestamp = self.get_file_timestamp(file_path)
        cached_timestamp = self.timestamps.get(file_key, 0)
        
        return current_timestamp > cached_timestamp
        
    def load_data(self, file_key):
        """åŠ è½½æˆ–è¿”å›ç¼“å­˜çš„æ•°æ®"""
        if file_key not in self.cache or self.should_reload(file_key):
            file_path = self.get_file_path(file_key)
            if not file_path or not os.path.exists(file_path):
                print(f"è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
                return pd.DataFrame()
                
            try:
                print(f"é‡æ–°åŠ è½½æ–‡ä»¶: {file_path}")
                df = pd.read_csv(file_path)
                self.cache[file_key] = df
                self.timestamps[file_key] = self.get_file_timestamp(file_path)
                return df
            except Exception as e:
                print(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return pd.DataFrame()
        else:
            print(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {file_key}")
            return self.cache[file_key].copy()
            
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.timestamps.clear()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¤šæ¿å—è‚¡ç¥¨ä»ªè¡¨ç›˜æœåŠ¡å™¨...")
    
    server = MultiPlateStockServer(port=5008)
    
    try:
        # å¯åŠ¨æ—¶åˆå§‹åŒ–åŠ¨æ€æ ‡é¢˜
        server._update_dynamic_titles()
        print("âœ… åŠ¨æ€æ ‡é¢˜åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ åŠ¨æ€æ ‡é¢˜åˆå§‹åŒ–å¤±è´¥: {e}")
    
    server.run(debug=True, use_reloader=False)


if __name__ == '__main__':
    main()
