"""
æ•°æ®å¤„ç†å™¨åŸºç±»
æä¾›é€šç”¨çš„æ•°æ®å¤„ç†åŠŸèƒ½å’Œæ¥å£è§„èŒƒ
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import logging
import time
from flask import jsonify, request


class BaseDataProcessor(ABC):
    """æ•°æ®å¤„ç†å™¨åŸºç±»"""
    
    def __init__(self, server_instance):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            server_instance: æœåŠ¡å™¨å®ä¾‹ï¼Œç”¨äºè®¿é—®æ•°æ®ç¼“å­˜å’Œå…¶ä»–èµ„æº
        """
        self.server = server_instance
        self.data_cache = server_instance.data_cache
        self.response_cache = server_instance.response_cache
        self.logger = server_instance.logger
    
    def get_request_params(self) -> Dict[str, Any]:
        """è·å–è¯·æ±‚å‚æ•°"""
        return dict(request.args) if hasattr(request, 'args') else {}
    
    def build_cache_params(self, **kwargs) -> Dict[str, Any]:
        """æ„å»ºç¼“å­˜å‚æ•°"""
        params = self.get_request_params()
        params.update(kwargs)
        return params
    
    def should_use_cache(self, endpoint: str, cache_params: Optional[Dict] = None, 
                        source_data: Optional[Dict] = None):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜"""
        return self.response_cache.should_use_cache(endpoint, cache_params, source_data)
    
    def store_cache(self, endpoint: str, cache_params: Optional[Dict] = None, 
                   source_data: Optional[Dict] = None, response_data=None):
        """å­˜å‚¨ç¼“å­˜"""
        self.response_cache.store_response(endpoint, cache_params, source_data, response_data)
    
    def error_response(self, message: str, status_code: int = 500):
        """è¿”å›é”™è¯¯å“åº”"""
        self.logger.error(message)
        return jsonify({"error": message}), status_code
    
    def _process_with_startup_cache(self, endpoint: str, original_method):
        """
        å¯åŠ¨ç¼“å­˜åŒ…è£…å™¨
        ä¸ºåŸæœ‰çš„å¤„ç†æ–¹æ³•æ·»åŠ å¯åŠ¨ç¼“å­˜åŠŸèƒ½
        
        Args:
            endpoint: APIç«¯ç‚¹è·¯å¾„
            original_method: åŸå§‹çš„æ•°æ®å¤„ç†æ–¹æ³•
            
        Returns:
            å¤„ç†åçš„å“åº”æ•°æ®
        """
        try:
            # å¯¹äºå¯åŠ¨ç¼“å­˜ï¼Œæˆ‘ä»¬ç®€åŒ–å‚æ•°å¤„ç†ï¼Œåªä½¿ç”¨endpointä½œä¸ºkey
            # å› ä¸ºå¯åŠ¨ç¼“å­˜ä¸»è¦ç”¨äºä¸ä¾èµ–è¯·æ±‚å‚æ•°çš„é™æ€æ•°æ®
            cache_params = None  # å¯åŠ¨ç¼“å­˜ä¸ä½¿ç”¨å‚æ•°
            
            # ğŸ” æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” å¯åŠ¨ç¼“å­˜æ£€æŸ¥: {endpoint}")
            print(f"  - cache_params: {cache_params}")
            
            # æ£€æŸ¥å¯åŠ¨ç¼“å­˜
            if hasattr(self.server, 'startup_cache') and self.server.startup_cache.is_startup_cached(endpoint, cache_params):
                self.logger.info(f"ğŸ”’ ä½¿ç”¨å¯åŠ¨æ—¶ç¼“å­˜æ•°æ®: {endpoint}")
                return self.server.startup_cache.get_startup_cache(endpoint, cache_params)
            
            # å¦‚æœæœ‰å¯åŠ¨ç¼“å­˜å¯¹è±¡ä½†æ²¡æœ‰ç¼“å­˜ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if hasattr(self.server, 'startup_cache'):
                cache_key = self.server.startup_cache._generate_startup_key(endpoint, cache_params)
                available_keys = list(self.server.startup_cache.startup_cache.keys())
                print(f"  - generated_key: {cache_key}")
                print(f"  - available_keys: {available_keys}")
                print(f"  - cache_exists: {cache_key in self.server.startup_cache.startup_cache}")
            
            # æ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡ŒåŸå§‹æ–¹æ³•
            self.logger.info(f"ğŸ”„ å¯åŠ¨ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œè®¡ç®—: {endpoint}")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è°ƒç”¨åŸå§‹å¤„ç†æ–¹æ³•
            response_data = original_method()
            
            # è®°å½•è®¡ç®—æ—¶é—´
            duration = time.time() - start_time
            self.logger.info(f"â±ï¸ è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            
            # å¦‚æœå“åº”æ˜¯ JSON æ ¼å¼ï¼Œæ·»åŠ ç¼“å­˜å…ƒæ•°æ®
            if hasattr(response_data, 'json') and response_data.json:
                data = response_data.json.copy()
                if isinstance(data, dict):
                    if 'metadata' not in data:
                        data['metadata'] = {}
                    data['metadata'].update({
                        'cached': False,
                        'cache_type': 'startup_once',
                        'calculatedAt': time.strftime("%Y-%m-%d %H:%M:%S"),
                        'calculation_duration': duration
                    })
                    response_data = jsonify(data)
            
            # å­˜å‚¨åˆ°å¯åŠ¨ç¼“å­˜
            if hasattr(self.server, 'startup_cache'):
                # ä½¿ç”¨ç›¸åŒçš„å‚æ•°ç­–ç•¥ï¼šå¯åŠ¨ç¼“å­˜ä¸ä½¿ç”¨å‚æ•°
                self.server.startup_cache.set_startup_cache(endpoint, None, response_data)
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨ç¼“å­˜å¤„ç†å¤±è´¥ {endpoint}: {e}")
            return self.error_response(f"å¤„ç†å¤±è´¥: {e}")
    
    def _process_with_response_cache(self, endpoint: str, original_method, cache_params: Optional[Dict] = None, 
                                   source_data: Optional[Dict] = None):
        """
        å“åº”ç¼“å­˜åŒ…è£…å™¨
        ä¸ºåŸæœ‰çš„å¤„ç†æ–¹æ³•æ·»åŠ å“åº”ç¼“å­˜åŠŸèƒ½
        
        Args:
            endpoint: APIç«¯ç‚¹è·¯å¾„
            original_method: åŸå§‹çš„æ•°æ®å¤„ç†æ–¹æ³•
            cache_params: ç¼“å­˜å‚æ•°
            source_data: æºæ•°æ®ç”¨äºç¼“å­˜æ£€æŸ¥
            
        Returns:
            å¤„ç†åçš„å“åº”æ•°æ®
        """
        try:
            if cache_params is None:
                cache_params = self.build_cache_params()
            
            # æ£€æŸ¥å“åº”ç¼“å­˜
            if self.should_use_cache(endpoint, cache_params, source_data):
                cached_response = self.response_cache.get_response(endpoint, cache_params)
                if cached_response:
                    self.logger.info(f"ğŸ”’ ä½¿ç”¨å“åº”ç¼“å­˜æ•°æ®: {endpoint}")
                    return cached_response
            
            # æ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡ŒåŸå§‹æ–¹æ³•
            self.logger.info(f"ğŸ”„ å“åº”ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œè®¡ç®—: {endpoint}")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è°ƒç”¨åŸå§‹å¤„ç†æ–¹æ³•
            response_data = original_method()
            
            # è®°å½•è®¡ç®—æ—¶é—´
            duration = time.time() - start_time
            self.logger.info(f"â±ï¸ è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            
            # å­˜å‚¨åˆ°å“åº”ç¼“å­˜
            self.store_cache(endpoint, cache_params, source_data, response_data)
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"å“åº”ç¼“å­˜å¤„ç†å¤±è´¥ {endpoint}: {e}")
            return self.error_response(f"å¤„ç†å¤±è´¥: {e}")
    
    @abstractmethod
    def process(self, *args, **kwargs):
        """å¤„ç†æ•°æ®çš„æŠ½è±¡æ–¹æ³•ï¼Œå­ç±»å¿…é¡»å®ç°"""
        pass
