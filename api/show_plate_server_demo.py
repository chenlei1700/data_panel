#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Author: chenlei
Date: 2024-01-20
Description: ç»¼åˆå›¾è¡¨æ¼”ç¤ºæœåŠ¡å™¨ - åŸºäºæ–°æ¡†æ¶é‡æ„ç‰ˆæœ¬
åŠŸèƒ½: æä¾›å¤šç§å›¾è¡¨ç±»å‹çš„ç»¼åˆæ¼”ç¤º:
     - å †å é¢ç§¯å›¾ (èµ„é‡‘æµå‘ã€æ¿å—è¡¨ç°ã€é£é™©åˆ†å¸ƒ)
     - æŠ˜çº¿å›¾ (è‚¡ä»·è¶‹åŠ¿)
     - æŸ±çŠ¶å›¾ (æˆäº¤é‡)
     - é¥¼å›¾ (æ¿å—åˆ†å¸ƒ)
     - ä»ªè¡¨ç›˜ (å¸‚åœºæƒ…ç»ª)
     - ç»„åˆå›¾ (ä»·æ ¼-æˆäº¤é‡)
     - æ•£ç‚¹å›¾ (é£é™©-æ”¶ç›Š)
     - æ™ºèƒ½è¡¨æ ¼ (æ”¯æŒå¤šç§èƒŒæ™¯è‰²è§„åˆ™)
"""

import time
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import plotly
import plotly.graph_objects as go
import os
import sys
import queue
from flask import request, Response, jsonify
from flask_cors import CORS

# å¯¼å…¥æ–°æ¡†æ¶åŸºç±»
from base_server import BaseStockServer

class StackedAreaDemoServer(BaseStockServer):
    """ç»¼åˆå›¾è¡¨æ¼”ç¤ºæœåŠ¡å™¨ - ç»§æ‰¿è‡ªBaseStockServer
    
    æä¾›å¤šç§å›¾è¡¨ç±»å‹çš„å®Œæ•´æ¼”ç¤º:
    - å †å é¢ç§¯å›¾ã€æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾
    - ä»ªè¡¨ç›˜ã€ç»„åˆå›¾ã€æ•£ç‚¹å›¾
    - æ™ºèƒ½è¡¨æ ¼ (æ”¯æŒæ¡ä»¶èƒŒæ™¯è‰²)
    """
    
    def __init__(self, port=5004):
        super().__init__(name="ç»¼åˆå›¾è¡¨æ¼”ç¤º", port=port)
        
        # æœåŠ¡ç‰¹å®šçš„é…ç½®
        self.stacked_data_cache = {}
        self.dynamic_titles = {
            "main_chart": "ä¸»è¦èµ„é‡‘æµå‘",
            "detail_table": "è¯¦ç»†æ•°æ®è¡¨"
        }
        self.selected_chart_type = "èµ„é‡‘æµå‘"
        self.latest_update = {
            "chart_type": "èµ„é‡‘æµå‘",
            "componentId": "stackedAreaChart1", 
            "timestamp": time.time()
        }
        self.sse_clients = []
        self.message_queue = queue.Queue()
        
        # åˆå§‹åŒ–æ‰€æœ‰ç±»å‹çš„æ¼”ç¤ºæ•°æ®
        self._init_all_demo_data()

    def _init_all_demo_data(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¼”ç¤ºæ•°æ®"""
        try:
            # å †å é¢ç§¯å›¾æ•°æ®
            self.fund_flow_data = self._generate_fund_flow_data()
            self.sector_performance_data = self._generate_sector_performance_data()
            self.risk_distribution_data = self._generate_risk_distribution_data()
            
            # å…¶ä»–å›¾è¡¨åŸºç¡€æ•°æ®å¯ä»¥åœ¨è¿™é‡Œé¢„ç”Ÿæˆ
            self.stock_list = ["è‚¡ç¥¨A", "è‚¡ç¥¨B", "è‚¡ç¥¨C", "è‚¡ç¥¨D", "è‚¡ç¥¨E"]
            self.time_segments = ["09:30", "10:00", "10:30", "11:00", "11:30", "14:00", "14:30", "15:00"]
            
            self.logger.info("æ‰€æœ‰æ¼”ç¤ºæ•°æ®åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"æ¼”ç¤ºæ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")
            # è®¾ç½®é»˜è®¤ç©ºæ•°æ®
            self.fund_flow_data = {}
            self.sector_performance_data = {}
            self.risk_distribution_data = {}
            self.stock_list = []
            self.time_segments = []

    def get_dashboard_config(self):
        """è·å–ä»ªè¡¨ç›˜é…ç½® - åŒ…å«å¤šç§å›¾è¡¨ç±»å‹çš„ç»¼åˆæ¼”ç¤º"""
        return {
            "layout": {
                "rows": 6,
                "cols": 3,
                "components": [
                    # ç¬¬ä¸€è¡Œ - å †å é¢ç§¯å›¾ï¼ˆä½¿ç”¨ä¸“é—¨ç»„ä»¶ï¼‰
                    {
                        "id": "stackedAreaChart1",
                        "type": "stackedAreaChart",
                        "dataSource": "/api/chart-data/fund-flow-stacked",
                        "title": "èµ„é‡‘æµå‘å †å é¢ç§¯å›¾",
                        "position": {"row": 0, "col": 0, "rowSpan": 1, "colSpan": 3},
                        "height": "650px"
                    },
                    # ç¬¬äºŒè¡Œ - ä½¿ç”¨é€šç”¨chartç±»å‹
                    {
                        "id": "lineChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/stock-trend-line",
                        "title": "è‚¡ä»·è¶‹åŠ¿æŠ˜çº¿å›¾",
                        "position": {"row": 1, "col": 0, "rowSpan": 1, "colSpan": 1},
                        "height": "600px"
                    },
                    {
                        "id": "barChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/volume-bar",
                        "title": "æˆäº¤é‡æŸ±çŠ¶å›¾",
                        "position": {"row": 1, "col": 1, "rowSpan": 1, "colSpan": 1},
                        "height": "600px"
                    },
                    {
                        "id": "pieChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/sector-distribution-pie",
                        "title": "æ¿å—åˆ†å¸ƒé¥¼å›¾",
                        "position": {"row": 1, "col": 2, "rowSpan": 1, "colSpan": 1},
                        "height": "600px"
                    },
                    # ç¬¬ä¸‰è¡Œ - å †å é¢ç§¯å›¾å’Œå…¶ä»–å›¾è¡¨
                    {
                        "id": "stackedAreaChart2",
                        "type": "stackedAreaChart",
                        "dataSource": "/api/chart-data/sector-performance-stacked",
                        "title": "æ¿å—è¡¨ç°å †å å›¾",
                        "position": {"row": 2, "col": 0, "rowSpan": 1, "colSpan": 1},
                        "height": "680px"
                    },
                    {
                        "id": "stackedAreaChart3",
                        "type": "stackedAreaChart",
                        "dataSource": "/api/chart-data/risk-distribution-stacked",
                        "title": "é£é™©åˆ†å¸ƒå †å å›¾",
                        "position": {"row": 2, "col": 1, "rowSpan": 1, "colSpan": 1},
                        "height": "680px"
                    },
                    {
                        "id": "gaugeChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/market-sentiment-gauge",
                        "title": "å¸‚åœºæƒ…ç»ªæŒ‡æ ‡",
                        "position": {"row": 2, "col": 2, "rowSpan": 1, "colSpan": 1},
                        "height": "680px"
                    },
                    # ç¬¬å››è¡Œ - è¡¨æ ¼ç»„ä»¶
                    {
                        "id": "table1",
                        "type": "table",
                        "dataSource": "/api/table-data/top-stocks",
                        "title": "çƒ­é—¨è‚¡ç¥¨æ’è¡Œæ¦œ",
                        "position": {"row": 3, "col": 0, "rowSpan": 1, "colSpan": 2},
                        "height": "600px"
                    },
                    {
                        "id": "table2",
                        "type": "table",
                        "dataSource": "/api/table-data/financial-indicators",
                        "title": "è´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”è¡¨",
                        "position": {"row": 3, "col": 2, "rowSpan": 1, "colSpan": 1},
                        "height": "600px"
                    },
                    # ç¬¬äº”è¡Œ - æ··åˆå›¾è¡¨ï¼ˆä½¿ç”¨é€šç”¨chartç±»å‹ï¼‰
                    {
                        "id": "comboChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/price-volume-combo",
                        "title": "ä»·æ ¼æˆäº¤é‡ç»„åˆå›¾",
                        "position": {"row": 4, "col": 0, "rowSpan": 1, "colSpan": 2},
                        "height": "620px"
                    },
                    {
                        "id": "scatterChart1",
                        "type": "chart",
                        "dataSource": "/api/chart-data/risk-return-scatter",
                        "title": "é£é™©æ”¶ç›Šæ•£ç‚¹å›¾",
                        "position": {"row": 4, "col": 2, "rowSpan": 1, "colSpan": 1},
                        "height": "620px"
                    },
                    # ç¬¬å…­è¡Œ - å®æ—¶æ•°æ®è¡¨æ ¼
                    {
                        "id": "table3",
                        "type": "table",
                        "dataSource": "/api/table-data/realtime-data",
                        "title": "å®æ—¶æ•°æ®ç›‘æ§è¡¨",
                        "position": {"row": 5, "col": 0, "rowSpan": 1, "colSpan": 3},
                        "height": "650px"
                    }
                ]
            }
        }

    def get_data_sources(self):
        """è·å–æ•°æ®æºé…ç½® - æ”¯æŒå¤šç§å›¾è¡¨ç±»å‹"""
        return {
            # å †å é¢ç§¯å›¾æ•°æ®æº
            "/api/chart-data/fund-flow-stacked": {
                "handler": "get_fund_flow_stacked_data",
                "description": "èµ„é‡‘æµå‘å †å é¢ç§¯å›¾æ•°æ®",
                "cache_ttl": 30
            },
            "/api/chart-data/sector-performance-stacked": {
                "handler": "get_sector_performance_stacked_data", 
                "description": "æ¿å—è¡¨ç°å †å é¢ç§¯å›¾æ•°æ®",
                "cache_ttl": 30
            },
            "/api/chart-data/risk-distribution-stacked": {
                "handler": "get_risk_distribution_stacked_data",
                "description": "é£é™©åˆ†å¸ƒå †å é¢ç§¯å›¾æ•°æ®", 
                "cache_ttl": 30
            },
            
            # æŠ˜çº¿å›¾æ•°æ®æº
            "/api/chart-data/stock-trend-line": {
                "handler": "get_stock_trend_line_data",
                "description": "è‚¡ä»·è¶‹åŠ¿æŠ˜çº¿å›¾æ•°æ®",
                "cache_ttl": 10
            },
            
            # æŸ±çŠ¶å›¾æ•°æ®æº
            "/api/chart-data/volume-bar": {
                "handler": "get_volume_bar_data",
                "description": "æˆäº¤é‡æŸ±çŠ¶å›¾æ•°æ®",
                "cache_ttl": 10
            },
            
            # é¥¼å›¾æ•°æ®æº
            "/api/chart-data/sector-distribution-pie": {
                "handler": "get_sector_distribution_pie_data",
                "description": "æ¿å—åˆ†å¸ƒé¥¼å›¾æ•°æ®",
                "cache_ttl": 60
            },
            
            # ä»ªè¡¨ç›˜æ•°æ®æº
            "/api/chart-data/market-sentiment-gauge": {
                "handler": "get_market_sentiment_gauge_data",
                "description": "å¸‚åœºæƒ…ç»ªæŒ‡æ ‡æ•°æ®",
                "cache_ttl": 30
            },
            
            # ç»„åˆå›¾æ•°æ®æº
            "/api/chart-data/price-volume-combo": {
                "handler": "get_price_volume_combo_data",
                "description": "ä»·æ ¼æˆäº¤é‡ç»„åˆå›¾æ•°æ®",
                "cache_ttl": 10
            },
            
            # æ•£ç‚¹å›¾æ•°æ®æº
            "/api/chart-data/risk-return-scatter": {
                "handler": "get_risk_return_scatter_data",
                "description": "é£é™©æ”¶ç›Šæ•£ç‚¹å›¾æ•°æ®",
                "cache_ttl": 60
            },
            
            # è¡¨æ ¼æ•°æ®æº
            "/api/table-data/top-stocks": {
                "handler": "get_top_stocks_table_data",
                "description": "çƒ­é—¨è‚¡ç¥¨æ’è¡Œæ¦œ",
                "cache_ttl": 30
            },
            "/api/table-data/financial-indicators": {
                "handler": "get_financial_indicators_table_data",
                "description": "è´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”è¡¨",
                "cache_ttl": 60
            },
            "/api/table-data/realtime-data": {
                "handler": "get_realtime_data_table_data",
                "description": "å®æ—¶æ•°æ®ç›‘æ§è¡¨",
                "cache_ttl": 5
            },
            "/api/table-data/stacked_summary": {
                "handler": "get_stacked_summary_table_data", 
                "description": "å †å æ•°æ®æ±‡æ€»è¡¨",
                "cache_ttl": 30
            }
        }

    def register_custom_routes(self):
        """æ³¨å†Œè‡ªå®šä¹‰è·¯ç”± - åŸºç±»ä¼šè‡ªåŠ¨è°ƒç”¨handlerï¼Œæ— éœ€æ‰‹å·¥æ³¨å†Œ"""
        # æ³¨å†ŒSSEå’Œæ›´æ–°ç›¸å…³è·¯ç”±
        self.app.add_url_rule('/api/dashboard/update',
                             'update_dashboard_stacked',
                             self.update_dashboard, methods=['POST'])
        
        self.app.add_url_rule('/api/dashboard/updates',
                             'dashboard_updates_stacked',
                             self.dashboard_updates, methods=['GET'])
        
        self.app.add_url_rule('/api/stacked/regenerate-data',
                             'regenerate_stacked_data',
                             self.regenerate_stacked_data, methods=['POST'])

    # ===== æ•°æ®å¤„ç†æ–¹æ³• =====
    
    def get_fund_flow_stacked_data(self):
        """è¿”å›èµ„é‡‘æµå‘å †å é¢ç§¯å›¾æ•°æ®"""
        try:
            # æ›´æ–°æ•°æ®ä»¥æ¨¡æ‹Ÿå®æ—¶å˜åŒ–
            self._update_fund_flow_data()
            
            time_segments = ["09:30", "10:00", "10:30", "11:00", "11:30", "14:00", "14:30", "15:00"]
            key_order = ["æ•£æˆ·èµ„é‡‘", "æ¸¸èµ„", "æœºæ„èµ„é‡‘", "å¤–èµ„", "ä¸»åŠ›èµ„é‡‘"]
            colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#FFA07A", "#98D8C8"]
            
            data = {}
            table_data = {}
            
            for time_str in time_segments:
                point_data = {}
                total_value = 0
                
                base_values = self.fund_flow_data.get(time_str, {})
                
                for key in key_order:
                    # ä»ç¼“å­˜è·å–åŸºç¡€å€¼ï¼Œæ·»åŠ éšæœºæ³¢åŠ¨
                    base_value = base_values.get(key, np.random.uniform(10, 40))
                    value = round(base_value + np.random.uniform(-2, 2), 1)
                    value = max(1.0, value)  # ç¡®ä¿éè´Ÿ
                    
                    point_data[key] = value
                    total_value += value
                
                data[time_str] = point_data
                table_data[time_str] = f"{total_value:.1f}äº¿"
            
            return jsonify({
                "stackedAreaData": {
                    "data": data,
                    "keyOrder": key_order,
                    "colors": colors
                },
                "xAxisValues": time_segments,
                "tableData": table_data
            })
        
        except Exception as e:
            self.logger.error(f"è·å–èµ„é‡‘æµå‘å †å æ•°æ®å¤±è´¥: {e}")
            return jsonify(self._generate_fallback_stacked_data("èµ„é‡‘æµå‘"))

    def get_sector_performance_stacked_data(self):
        """è¿”å›æ¿å—è¡¨ç°å †å é¢ç§¯å›¾æ•°æ®"""
        try:
            time_segments = ["09:30", "10:30", "11:30", "14:00", "15:00"]
            key_order = ["ç§‘æŠ€æ¿å—", "é‡‘èæ¿å—", "åŒ»è¯æ¿å—", "æ¶ˆè´¹æ¿å—", "èƒ½æºæ¿å—"]
            colors = ["#E74C3C", "#3498DB", "#2ECC71", "#F39C12", "#9B59B6"]
            
            data = {}
            table_data = {}
            
            for time_str in time_segments:
                point_data = {}
                total_value = 0
                
                base_values = self.sector_performance_data.get(time_str, {})
                
                for key in key_order:
                    # ç”Ÿæˆæ¿å—è¡¨ç°æ•°æ®ï¼ˆæ¶¨å¹…ç™¾åˆ†æ¯”è½¬æ¢ä¸ºæ­£å€¼ï¼‰
                    base_value = base_values.get(key, np.random.uniform(-5, 15))
                    # è½¬æ¢ä¸ºæ­£å€¼ç”¨äºé¢ç§¯å›¾æ˜¾ç¤º
                    display_value = max(0.1, base_value + 10)  # åŠ 10ç¡®ä¿éƒ½æ˜¯æ­£å€¼
                    value = round(display_value, 1)
                    
                    point_data[key] = value
                    total_value += value
                
                data[time_str] = point_data
                table_data[time_str] = f"{total_value:.1f}"
            
            return jsonify({
                "stackedAreaData": {
                    "data": data,
                    "keyOrder": key_order,
                    "colors": colors
                },
                "xAxisValues": time_segments,
                "tableData": table_data
            })
        
        except Exception as e:
            self.logger.error(f"è·å–æ¿å—è¡¨ç°å †å æ•°æ®å¤±è´¥: {e}")
            return jsonify(self._generate_fallback_stacked_data("æ¿å—è¡¨ç°"))

    def get_risk_distribution_stacked_data(self):
        """è¿”å›é£é™©åˆ†å¸ƒå †å é¢ç§¯å›¾æ•°æ®"""
        try:
            time_segments = ["09:30", "10:30", "11:30", "14:00", "15:00"]
            key_order = ["ä½é£é™©", "ä¸­ä½é£é™©", "ä¸­ç­‰é£é™©", "ä¸­é«˜é£é™©", "é«˜é£é™©"]
            colors = ["#27AE60", "#F1C40F", "#E67E22", "#E74C3C", "#8E44AD"]
            
            data = {}
            table_data = {}
            
            for time_str in time_segments:
                point_data = {}
                total_value = 100  # é£é™©åˆ†å¸ƒæ€»å’Œä¸º100%
                remaining_value = total_value
                
                base_values = self.risk_distribution_data.get(time_str, {})
                
                for i, key in enumerate(key_order):
                    if i == len(key_order) - 1:  # æœ€åä¸€ä¸ªé¡¹ç›®
                        value = remaining_value
                    else:
                        base_percentage = base_values.get(key, 20)
                        value = round(base_percentage + np.random.uniform(-3, 3), 1)
                        value = max(1.0, min(value, remaining_value - len(key_order) + i))
                        remaining_value -= value
                    
                    point_data[key] = value
                
                data[time_str] = point_data
                table_data[time_str] = "100%"
            
            return jsonify({
                "stackedAreaData": {
                    "data": data,
                    "keyOrder": key_order,
                    "colors": colors
                },
                "xAxisValues": time_segments,
                "tableData": table_data
            })
        
        except Exception as e:
            self.logger.error(f"è·å–é£é™©åˆ†å¸ƒå †å æ•°æ®å¤±è´¥: {e}")
            return jsonify(self._generate_fallback_stacked_data("é£é™©åˆ†å¸ƒ"))

    def get_stacked_summary_table_data(self):
        """è¿”å›å †å æ•°æ®æ±‡æ€»è¡¨"""
        try:
            columns = [
                {"field": "time_segment", "header": "æ—¶é—´æ®µ"},
                {"field": "total_fund", "header": "æ€»èµ„é‡‘æµå…¥(äº¿)", "backgroundColor": "redGreen"},
                {"field": "main_fund_ratio", "header": "ä¸»åŠ›å æ¯”(%)", "backgroundColor": "redGreen"},
                {"field": "active_sectors", "header": "æ´»è·ƒæ¿å—æ•°"},
                {"field": "risk_level", "header": "æ•´ä½“é£é™©ç­‰çº§"},
                {"field": "trend", "header": "è¶‹åŠ¿", "backgroundColor": "redGreen"}
            ]
            
            rows = []
            time_segments = ["09:30", "10:00", "10:30", "11:00", "11:30", "14:00", "14:30", "15:00"]
            
            for time_str in time_segments:
                # æ¨¡æ‹Ÿæ±‡æ€»æ•°æ®
                total_fund = round(np.random.uniform(80, 150), 1)
                main_fund_ratio = round(np.random.uniform(20, 45), 1)
                active_sectors = np.random.randint(3, 8)
                risk_levels = ["ä½", "ä¸­ä½", "ä¸­ç­‰", "ä¸­é«˜", "é«˜"]
                risk_level = np.random.choice(risk_levels)
                trends = ["ä¸Šæ¶¨", "ä¸‹è·Œ", "éœ‡è¡"]
                trend = np.random.choice(trends)
                
                row = {
                    "time_segment": time_str,
                    "total_fund": total_fund,
                    "main_fund_ratio": main_fund_ratio,
                    "active_sectors": active_sectors,
                    "risk_level": risk_level,
                    "trend": trend
                }
                rows.append(row)
            
            return jsonify({
                "columns": columns,
                "rows": rows
            })
        
        except Exception as e:
            self.logger.error(f"è·å–å †å æ±‡æ€»è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    # ===== SSE å’Œæ›´æ–°ç›¸å…³æ–¹æ³• =====
    
    def update_dashboard(self):
        """æ¥æ”¶é¡µé¢æ›´æ–°è¯·æ±‚"""
        data = request.json
        self.logger.info(f"æ”¶åˆ°å †å å›¾æ›´æ–°è¯·æ±‚: {data}")
        
        params = data.get('params', {})
        chart_type = params.get('chart_type', 'èµ„é‡‘æµå‘') if isinstance(params, dict) else 'èµ„é‡‘æµå‘'
        
        self.selected_chart_type = chart_type
        
        self.latest_update = {
            "componentId": data.get('componentId', 'stackedAreaChart1'),
            "params": params,
            "timestamp": time.time(),
            "action": "config_update",
            "chart_type": chart_type
        }
        
        update_message = {
            "action": "reload_config",
            "chart_type": chart_type,
            "timestamp": time.time()
        }
        self._send_update_to_clients(update_message)
        
        return jsonify({
            "status": "success",
            "message": "Stacked chart update request sent",
            "chart_type": chart_type
        })

    def dashboard_updates(self):
        """SSEäº‹ä»¶æµ"""
        def event_stream():
            client_queue = queue.Queue()
            client_id = f"stacked_client_{len(self.sse_clients)}_{time.time()}"
            
            try:
                self.sse_clients.append(client_queue)
                self.logger.info(f"å †å å›¾SSEå®¢æˆ·ç«¯è¿æ¥: {client_id}ï¼Œå½“å‰æ€»è¿æ¥æ•°: {len(self.sse_clients)}")
                
                connection_info = {
                    "type": "connection_established",
                    "client_id": client_id,
                    "timestamp": time.time(),
                    "server_status": "online"
                }
                yield f"data: {json.dumps(connection_info)}\n\n"
                yield f"data: {json.dumps(self.latest_update)}\n\n"
                
                while True:
                    try:
                        message = client_queue.get(block=True, timeout=10)
                        yield message
                    except queue.Empty:
                        heartbeat = {
                            "type": "heartbeat",
                            "client_id": client_id,
                            "timestamp": time.time(),
                            "server_time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "active_connections": len(self.sse_clients),
                            "stacked_status": "running"
                        }
                        yield f"data: {json.dumps(heartbeat)}\n\n"
                        continue
                    except GeneratorExit:
                        self.logger.info(f"å †å å›¾SSEå®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€: {client_id}")
                        break
                        
            except Exception as e:
                self.logger.error(f"å †å å›¾SSEè¿æ¥å¼‚å¸¸ {client_id}: {e}")
            finally:
                if client_queue in self.sse_clients:
                    self.sse_clients.remove(client_queue)
                    self.logger.info(f"å †å å›¾SSEå®¢æˆ·ç«¯æ¸…ç†: {client_id}ï¼Œå‰©ä½™è¿æ¥æ•°: {len(self.sse_clients)}")
        
        response = Response(event_stream(), mimetype="text/event-stream")
        response.headers.update({
            'Cache-Control': 'no-cache, no-store, must-revalidate',
            'Pragma': 'no-cache',
            'Expires': '0',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Cache-Control',
            'Keep-Alive': 'timeout=30, max=1000'
        })
        return response

    def regenerate_stacked_data(self):
        """é‡æ–°ç”Ÿæˆå †å æ•°æ®"""
        try:
            self._init_stacked_data()
            self.logger.info("å †å é¢ç§¯å›¾æ•°æ®å·²é‡æ–°ç”Ÿæˆ")
            
            update_message = {
                "action": "data_regenerate",
                "timestamp": time.time()
            }
            self._send_update_to_clients(update_message)
            
            return jsonify({
                "status": "success",
                "message": "å †å é¢ç§¯å›¾æ•°æ®å·²é‡æ–°ç”Ÿæˆ"
            })
        except Exception as e:
            self.logger.error(f"é‡æ–°ç”Ÿæˆå †å æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

    # ===== è¾…åŠ©æ–¹æ³• =====
    
    def _send_update_to_clients(self, data):
        """å‘é€æ›´æ–°åˆ°æ‰€æœ‰SSEå®¢æˆ·ç«¯"""
        for client in list(self.sse_clients):
            try:
                client.put(f"data: {json.dumps(data)}\n\n")
            except:
                self.sse_clients.remove(client)

    def _generate_fund_flow_data(self):
        """ç”Ÿæˆèµ„é‡‘æµå‘åŸºç¡€æ•°æ®"""
        time_segments = ["09:30", "10:00", "10:30", "11:00", "11:30", "14:00", "14:30", "15:00"]
        key_order = ["æ•£æˆ·èµ„é‡‘", "æ¸¸èµ„", "æœºæ„èµ„é‡‘", "å¤–èµ„", "ä¸»åŠ›èµ„é‡‘"]
        
        fund_data = {}
        for time_str in time_segments:
            point_data = {}
            for key in key_order:
                # åŸºç¡€å€¼ï¼Œåç»­ä¼šæ·»åŠ éšæœºæ³¢åŠ¨
                base_value = np.random.uniform(15, 35)
                # æ·»åŠ æ—¶é—´ç›¸å…³çš„è¶‹åŠ¿
                if time_str in ["10:30", "14:30"]:  # æ´»è·ƒæ—¶æ®µ
                    base_value *= 1.2
                elif time_str in ["11:30", "15:00"]:  # æ”¶ç›˜å‰
                    base_value *= 0.9
                
                point_data[key] = round(base_value, 1)
            
            fund_data[time_str] = point_data
        
        return fund_data

    def _generate_sector_performance_data(self):
        """ç”Ÿæˆæ¿å—è¡¨ç°åŸºç¡€æ•°æ®"""
        time_segments = ["09:30", "10:30", "11:30", "14:00", "15:00"]
        key_order = ["ç§‘æŠ€æ¿å—", "é‡‘èæ¿å—", "åŒ»è¯æ¿å—", "æ¶ˆè´¹æ¿å—", "èƒ½æºæ¿å—"]
        
        sector_data = {}
        for time_str in time_segments:
            point_data = {}
            for key in key_order:
                # ç”Ÿæˆæ¿å—æ¶¨è·Œå¹…ï¼ˆ-5% åˆ° 15%ï¼‰
                performance = np.random.uniform(-5, 15)
                point_data[key] = round(performance, 1)
            
            sector_data[time_str] = point_data
        
        return sector_data

    def _generate_risk_distribution_data(self):
        """ç”Ÿæˆé£é™©åˆ†å¸ƒåŸºç¡€æ•°æ®"""
        time_segments = ["09:30", "10:30", "11:30", "14:00", "15:00"]
        key_order = ["ä½é£é™©", "ä¸­ä½é£é™©", "ä¸­ç­‰é£é™©", "ä¸­é«˜é£é™©", "é«˜é£é™©"]
        
        risk_data = {}
        for time_str in time_segments:
            point_data = {}
            # ç¡®ä¿æ€»å’Œä¸º100%
            percentages = np.random.dirichlet([2, 3, 4, 2, 1]) * 100  # åå‘ä¸­ç­‰é£é™©
            
            for i, key in enumerate(key_order):
                point_data[key] = round(percentages[i], 1)
            
            risk_data[time_str] = point_data
        
        return risk_data

    def _update_fund_flow_data(self):
        """æ›´æ–°èµ„é‡‘æµå‘æ•°æ®ï¼ˆæ¨¡æ‹Ÿå®æ—¶å˜åŒ–ï¼‰"""
        for time_str, point_data in self.fund_flow_data.items():
            for key in point_data:
                # å°å¹…éšæœºè°ƒæ•´
                current_value = point_data[key]
                change = np.random.uniform(-1, 1)
                new_value = max(5.0, current_value + change)
                self.fund_flow_data[time_str][key] = round(new_value, 1)

    def _generate_fallback_stacked_data(self, data_type):
        """ç”Ÿæˆåå¤‡å †å æ•°æ®"""
        time_segments = ["09:30", "10:30", "11:30", "14:00", "15:00"]
        
        if data_type == "èµ„é‡‘æµå‘":
            key_order = ["æ•£æˆ·èµ„é‡‘", "æ¸¸èµ„", "æœºæ„èµ„é‡‘", "å¤–èµ„", "ä¸»åŠ›èµ„é‡‘"]
            colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#FFA07A", "#98D8C8"]
        elif data_type == "æ¿å—è¡¨ç°":
            key_order = ["ç§‘æŠ€æ¿å—", "é‡‘èæ¿å—", "åŒ»è¯æ¿å—", "æ¶ˆè´¹æ¿å—", "èƒ½æºæ¿å—"]
            colors = ["#E74C3C", "#3498DB", "#2ECC71", "#F39C12", "#9B59B6"]
        else:  # é£é™©åˆ†å¸ƒ
            key_order = ["ä½é£é™©", "ä¸­ä½é£é™©", "ä¸­ç­‰é£é™©", "ä¸­é«˜é£é™©", "é«˜é£é™©"]
            colors = ["#27AE60", "#F1C40F", "#E67E22", "#E74C3C", "#8E44AD"]
        
        data = {}
        table_data = {}
        
        for time_str in time_segments:
            point_data = {}
            total_value = 0
            
            for key in key_order:
                value = round(np.random.uniform(10, 30), 1)
                point_data[key] = value
                total_value += value
            
            data[time_str] = point_data
            table_data[time_str] = f"{total_value:.1f}"
        
        return {
            "stackedAreaData": {
                "data": data,
                "keyOrder": key_order,
                "colors": colors
            },
            "xAxisValues": time_segments,
            "tableData": table_data
        }

    # ===== æ–°å¢å›¾è¡¨æ•°æ®å¤„ç†æ–¹æ³• =====
    
    def get_stock_trend_line_data(self):
        """è·å–è‚¡ä»·è¶‹åŠ¿æŠ˜çº¿å›¾æ•°æ®"""
        try:
            # ç”Ÿæˆè¿‡å»30å¤©çš„è‚¡ä»·æ•°æ®
            dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
            base_price = 100.0
            
            stocks = ["è‚¡ç¥¨A", "è‚¡ç¥¨B", "è‚¡ç¥¨C"]
            colors = ["#2196F3", "#FF5722", "#4CAF50"]
            
            plotly_traces = []
            for i, stock in enumerate(stocks):
                prices = []
                current_price = base_price + np.random.uniform(-20, 20)
                
                for _ in range(30):
                    change = np.random.uniform(-0.05, 0.05)  # æ—¥å˜åŒ–å¹…åº¦
                    current_price = current_price * (1 + change)
                    prices.append(round(current_price, 2))
                
                plotly_traces.append({
                    "x": [date.strftime('%m-%d') for date in dates],
                    "y": prices,
                    "name": stock,
                    "mode": "lines+markers",
                    "line": {"color": colors[i], "width": 2},
                    "marker": {"size": 4}
                })
            
            return jsonify({
                "chartType": "scatter",
                "data": plotly_traces,
                "layout": {
                    "title": "è‚¡ä»·è¶‹åŠ¿",
                    "xaxis": {"title": "æ—¥æœŸ"},
                    "yaxis": {"title": "ä»·æ ¼(å…ƒ)"}
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–æŠ˜çº¿å›¾æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_volume_bar_data(self):
        """è·å–æˆäº¤é‡æŸ±çŠ¶å›¾æ•°æ®"""
        try:
            time_segments = ["09:30", "10:00", "10:30", "11:00", "11:30", "14:00", "14:30", "15:00"]
            
            volumes = []
            colors = []
            for _ in time_segments:
                volume = round(np.random.uniform(1000, 8000), 1)
                volumes.append(volume)
                # æˆäº¤é‡å¤§äº5000ç”¨çº¢è‰²ï¼Œå¦åˆ™ç”¨ç»¿è‰²
                colors.append("#FF5722" if volume > 5000 else "#4CAF50")
            
            return jsonify({
                "chartType": "bar",
                "data": [{
                    "x": time_segments,
                    "y": volumes,
                    "name": "æˆäº¤é‡",
                    "type": "bar",
                    "marker": {
                        "color": colors
                    }
                }],
                "layout": {
                    "title": "äº¤æ˜“æ—¶æ®µæˆäº¤é‡",
                    "xaxis": {"title": "æ—¶é—´"},
                    "yaxis": {"title": "æˆäº¤é‡(ä¸‡æ‰‹)"}
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–æŸ±çŠ¶å›¾æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_sector_distribution_pie_data(self):
        """è·å–æ¿å—åˆ†å¸ƒé¥¼å›¾æ•°æ®"""
        try:
            sectors = ["ç§‘æŠ€", "é‡‘è", "åŒ»è¯", "æ¶ˆè´¹", "èƒ½æº", "åœ°äº§", "åˆ¶é€ "]
            colors = ["#2196F3", "#FF5722", "#4CAF50", "#FF9800", "#9C27B0", "#607D8B", "#795548"]
            
            values = []
            for _ in sectors:
                value = round(np.random.uniform(8, 25), 1)
                values.append(value)
            
            return jsonify({
                "chartType": "pie",
                "data": [{
                    "labels": sectors,
                    "values": values,
                    "type": "pie",
                    "marker": {
                        "colors": colors
                    },
                    "textinfo": "label+percent",
                    "hovertemplate": "<b>%{label}</b><br>å æ¯”: %{percent}<br>å€¼: %{value}<extra></extra>",
                    "hole": 0.3  # æ·»åŠ ç”œç”œåœˆæ•ˆæœ
                }],
                "layout": {
                    "title": {"text": "æ¿å—èµ„é‡‘åˆ†å¸ƒ", "x": 0.5},
                    "showlegend": True,
                    "margin": {"t": 40, "l": 20, "r": 20, "b": 20},
                    "font": {"size": 12}
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–é¥¼å›¾æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_market_sentiment_gauge_data(self):
        """è·å–å¸‚åœºæƒ…ç»ªä»ªè¡¨ç›˜æ•°æ®"""
        try:
            # ç”Ÿæˆ0-100çš„å¸‚åœºæƒ…ç»ªæŒ‡æ•°
            sentiment_score = round(np.random.uniform(20, 90), 1)
            
            # ä½¿ç”¨ Plotly çš„ indicator ç±»å‹
            return jsonify({
                "chartType": "indicator",
                "data": [{
                    "type": "indicator",
                    "mode": "gauge+number+delta",
                    "value": sentiment_score,
                    "domain": {"x": [0, 1], "y": [0, 1]},
                    "title": {"text": "å¸‚åœºæƒ…ç»ªæŒ‡æ•°"},
                    "delta": {"reference": 50},
                    "gauge": {
                        "axis": {"range": [None, 100]},
                        "bar": {"color": "darkblue"},
                        "steps": [
                            {"range": [0, 30], "color": "lightgray"},
                            {"range": [30, 70], "color": "gray"},
                            {"range": [70, 100], "color": "lightgreen"}
                        ],
                        "threshold": {
                            "line": {"color": "red", "width": 4},
                            "thickness": 0.75,
                            "value": 90
                        }
                    }
                }],
                "layout": {
                    "title": "å¸‚åœºæƒ…ç»ªä»ªè¡¨ç›˜"
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_price_volume_combo_data(self):
        """è·å–ä»·æ ¼æˆäº¤é‡ç»„åˆå›¾æ•°æ®"""
        try:
            dates = pd.date_range(start='2024-01-01', periods=20, freq='D')
            
            prices = []
            volumes = []
            base_price = 50.0
            
            for _ in range(20):
                # ä»·æ ¼æ•°æ®
                change = np.random.uniform(-0.03, 0.03)
                base_price = base_price * (1 + change)
                prices.append(round(base_price, 2))
                
                # æˆäº¤é‡æ•°æ®
                volume = round(np.random.uniform(2000, 10000), 0)
                volumes.append(volume)
            
            return jsonify({
                "chartType": "scatter",
                "data": [
                    {
                        "x": [date.strftime('%m-%d') for date in dates],
                        "y": prices,
                        "name": "è‚¡ä»·",
                        "mode": "lines+markers",
                        "line": {"color": "#2196F3"},
                        "yaxis": "y"
                    },
                    {
                        "x": [date.strftime('%m-%d') for date in dates],
                        "y": volumes,
                        "name": "æˆäº¤é‡",
                        "type": "bar",
                        "marker": {"color": "#FF5722"},
                        "yaxis": "y2"
                    }
                ],
                "layout": {
                    "title": "ä»·æ ¼æˆäº¤é‡ç»„åˆå›¾",
                    "xaxis": {"title": "æ—¥æœŸ"},
                    "yaxis": {
                        "title": "ä»·æ ¼(å…ƒ)",
                        "side": "left"
                    },
                    "yaxis2": {
                        "title": "æˆäº¤é‡(ä¸‡æ‰‹)",
                        "side": "right",
                        "overlaying": "y"
                    }
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–ç»„åˆå›¾æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_risk_return_scatter_data(self):
        """è·å–é£é™©æ”¶ç›Šæ•£ç‚¹å›¾æ•°æ®"""
        try:
            stocks = ["è‚¡ç¥¨A", "è‚¡ç¥¨B", "è‚¡ç¥¨C", "è‚¡ç¥¨D", "è‚¡ç¥¨E", "è‚¡ç¥¨F", "è‚¡ç¥¨G", "è‚¡ç¥¨H"]
            
            x_data = []  # é£é™©å€¼
            y_data = []  # æ”¶ç›Šç‡
            sizes = []   # æ°”æ³¡å¤§å°
            names = []   # è‚¡ç¥¨åç§°
            
            for stock in stocks:
                risk = round(np.random.uniform(5, 25), 2)  # é£é™©å€¼ 5-25%
                return_rate = round(np.random.uniform(-15, 30), 2)  # æ”¶ç›Šç‡ -15% åˆ° 30%
                size = round(np.random.uniform(20, 100), 0)  # æ°”æ³¡å¤§å°ä»£è¡¨å¸‚å€¼
                
                x_data.append(risk)
                y_data.append(return_rate)
                sizes.append(size)
                names.append(stock)
            
            return jsonify({
                "chartType": "scatter",
                "data": [{
                    "x": x_data,
                    "y": y_data,
                    "mode": "markers",
                    "type": "scatter",
                    "text": names,
                    "marker": {
                        "size": sizes,
                        "sizemode": "diameter",
                        "sizeref": 2.*max(sizes)/(40.**2),
                        "sizemin": 4,
                        "color": y_data,
                        "colorscale": "Viridis",
                        "showscale": True,
                        "colorbar": {"title": "æ”¶ç›Šç‡(%)"}
                    },
                    "name": "è‚¡ç¥¨é£é™©æ”¶ç›Š"
                }],
                "layout": {
                    "title": "è‚¡ç¥¨é£é™©æ”¶ç›Šæ•£ç‚¹å›¾",
                    "xaxis": {"title": "é£é™©(%)"},
                    "yaxis": {"title": "æ”¶ç›Šç‡(%)"},
                    "hovermode": "closest"
                }
            })
            
        except Exception as e:
            self.logger.error(f"è·å–æ•£ç‚¹å›¾æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    # ===== æ–°å¢è¡¨æ ¼æ•°æ®å¤„ç†æ–¹æ³• =====
    
    def get_top_stocks_table_data(self):
        """è·å–çƒ­é—¨è‚¡ç¥¨æ’è¡Œæ¦œè¡¨æ ¼æ•°æ®"""
        try:
            self.logger.info("å¼€å§‹ç”Ÿæˆçƒ­é—¨è‚¡ç¥¨è¡¨æ ¼æ•°æ®")
            
            # æ–°æ ¼å¼ï¼šç›´æ¥åœ¨columnsä¸­åŒ…å«backgroundColoré…ç½®
            columns = [
                {"field": "æ’å", "header": "æ’å"},
                {"field": "è‚¡ç¥¨ä»£ç ", "header": "è‚¡ç¥¨ä»£ç "},
                {"field": "è‚¡ç¥¨åç§°", "header": "è‚¡ç¥¨åç§°"},
                {"field": "ç°ä»·(å…ƒ)", "header": "ç°ä»·(å…ƒ)", "backgroundColor": "highLow"},
                {"field": "æ¶¨è·Œå¹…(%)", "header": "æ¶¨è·Œå¹…(%)", "backgroundColor": "redGreen"},
                {"field": "æˆäº¤é‡(ä¸‡æ‰‹)", "header": "æˆäº¤é‡(ä¸‡æ‰‹)", "backgroundColor": "highLow"},
                {"field": "å¸‚å€¼(äº¿)", "header": "å¸‚å€¼(äº¿)", "backgroundColor": "highLow"},
                {"field": "å¸‚ç›ˆç‡", "header": "å¸‚ç›ˆç‡", "backgroundColor": "range"}
            ]
            
            rows = []
            for i in range(1, 21):  # ç”Ÿæˆ20åªè‚¡ç¥¨
                change_rate = round(np.random.uniform(-10, 10), 2)
                current_price = round(np.random.uniform(10, 200), 2)
                volume = int(round(np.random.uniform(1000, 50000), 0))
                market_value = round(np.random.uniform(50, 2000), 1)
                pe_ratio = round(np.random.uniform(5, 50), 1)
                
                row = {
                    "æ’å": int(i),
                    "è‚¡ç¥¨ä»£ç ": f"{6000 + i:04d}",
                    "è‚¡ç¥¨åç§°": f"è‚¡ç¥¨{chr(65 + (i-1) % 26)}",
                    "ç°ä»·(å…ƒ)": float(current_price),
                    "æ¶¨è·Œå¹…(%)": change_rate,
                    "æˆäº¤é‡(ä¸‡æ‰‹)": float(volume),
                    "å¸‚å€¼(äº¿)": float(market_value),
                    "å¸‚ç›ˆç‡": float(pe_ratio)
                }
                rows.append(row)
            
            result = {
                "columns": columns,
                "rows": rows
            }
            
            self.logger.info(f"ç”Ÿæˆè¡¨æ ¼æ•°æ®å®Œæˆ: {len(columns)} åˆ—, {len(rows)} è¡Œ")
            self.logger.debug(f"è¡¨æ ¼æ•°æ®ç»“æ„: columns={[c['field'] for c in columns[:3]]}, first_row_keys={list(rows[0].keys())[:3] if rows else 'empty'}")
            
            return jsonify(result)
            
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨è‚¡ç¥¨è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_financial_indicators_table_data(self):
        """è·å–è´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”è¡¨æ•°æ®"""
        try:
            # æ–°æ ¼å¼ï¼šç›´æ¥åœ¨columnsä¸­åŒ…å«backgroundColoré…ç½®
            columns = [
                {"field": "è´¢åŠ¡æŒ‡æ ‡", "header": "è´¢åŠ¡æŒ‡æ ‡"},
                {"field": "è‚¡ç¥¨A", "header": "è‚¡ç¥¨A", "backgroundColor": "performance"},
                {"field": "è‚¡ç¥¨B", "header": "è‚¡ç¥¨B", "backgroundColor": "performance"},
                {"field": "è‚¡ç¥¨C", "header": "è‚¡ç¥¨C", "backgroundColor": "performance"},
                {"field": "è¡Œä¸šå‡å€¼", "header": "è¡Œä¸šå‡å€¼"}
            ]
            
            indicators = [
                "å‡€èµ„äº§æ”¶ç›Šç‡(%)", "æ¯›åˆ©ç‡(%)", "å‡€åˆ©ç‡(%)", "èµ„äº§è´Ÿå€ºç‡(%)",
                "æµåŠ¨æ¯”ç‡", "é€ŸåŠ¨æ¯”ç‡", "å­˜è´§å‘¨è½¬ç‡", "åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡"
            ]
            
            rows = []
            for indicator in indicators:
                row = {
                    "è´¢åŠ¡æŒ‡æ ‡": indicator,
                    "è‚¡ç¥¨A": round(np.random.uniform(5, 25), 2),
                    "è‚¡ç¥¨B": round(np.random.uniform(5, 25), 2),
                    "è‚¡ç¥¨C": round(np.random.uniform(5, 25), 2),
                    "è¡Œä¸šå‡å€¼": round(np.random.uniform(10, 20), 2)
                }
                rows.append(row)
            
            return jsonify({
                "columns": columns,
                "rows": rows
            })
            
        except Exception as e:
            self.logger.error(f"è·å–è´¢åŠ¡æŒ‡æ ‡è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_realtime_data_table_data(self):
        """è·å–å®æ—¶æ•°æ®ç›‘æ§è¡¨æ•°æ®"""
        try:
            # æ–°æ ¼å¼ï¼šç›´æ¥åœ¨columnsä¸­åŒ…å«backgroundColoré…ç½®
            columns = [
                {"field": "æ—¶é—´", "header": "æ—¶é—´"},
                {"field": "APIçŠ¶æ€", "header": "APIçŠ¶æ€", "backgroundColor": "status"},
                {"field": "å“åº”æ—¶é—´(ms)", "header": "å“åº”æ—¶é—´(ms)", "backgroundColor": "threshold", "thresholds": [100, 300]},
                {"field": "åœ¨çº¿ç”¨æˆ·", "header": "åœ¨çº¿ç”¨æˆ·", "backgroundColor": "highLow"},
                {"field": "CPUä½¿ç”¨ç‡(%)", "header": "CPUä½¿ç”¨ç‡(%)", "backgroundColor": "utilization"},
                {"field": "å†…å­˜ä½¿ç”¨ç‡(%)", "header": "å†…å­˜ä½¿ç”¨ç‡(%)", "backgroundColor": "utilization"},
                {"field": "ç£ç›˜ä½¿ç”¨ç‡(%)", "header": "ç£ç›˜ä½¿ç”¨ç‡(%)", "backgroundColor": "utilization"},
                {"field": "ç½‘ç»œIO(MB/s)", "header": "ç½‘ç»œIO(MB/s)", "backgroundColor": "highLow"}
            ]
            
            rows = []
            current_time = datetime.now()
            
            for i in range(10):  # ç”Ÿæˆ10æ¡å®æ—¶è®°å½•
                timestamp = (current_time - timedelta(minutes=i)).strftime("%H:%M:%S")
                api_status = np.random.choice(["æ­£å¸¸", "è­¦å‘Š", "å¼‚å¸¸"], p=[0.8, 0.15, 0.05])
                response_time = round(np.random.uniform(50, 500), 0)
                cpu_usage = round(np.random.uniform(20, 90), 1)
                memory_usage = round(np.random.uniform(40, 85), 1)
                disk_usage = round(np.random.uniform(30, 75), 1)
                
                row = {
                    "æ—¶é—´": timestamp,
                    "APIçŠ¶æ€": api_status,
                    "å“åº”æ—¶é—´(ms)": response_time,
                    "åœ¨çº¿ç”¨æˆ·": round(np.random.uniform(100, 1000), 0),
                    "CPUä½¿ç”¨ç‡(%)": cpu_usage,
                    "å†…å­˜ä½¿ç”¨ç‡(%)": memory_usage,
                    "ç£ç›˜ä½¿ç”¨ç‡(%)": disk_usage,
                    "ç½‘ç»œIO(MB/s)": round(np.random.uniform(1, 50), 2)
                }
                rows.append(row)
            
            return jsonify({
                "columns": columns,
                "rows": rows
            })
            
        except Exception as e:
            self.logger.error(f"è·å–å®æ—¶ç›‘æ§è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ç»¼åˆå›¾è¡¨æ¼”ç¤ºæœåŠ¡å™¨...")
    print("ğŸ“Š æ”¯æŒçš„å›¾è¡¨ç±»å‹:")
    print("   - å †å é¢ç§¯å›¾ (èµ„é‡‘æµå‘ã€æ¿å—è¡¨ç°ã€é£é™©åˆ†å¸ƒ)")
    print("   - æŠ˜çº¿å›¾ (è‚¡ä»·è¶‹åŠ¿)")
    print("   - æŸ±çŠ¶å›¾ (æˆäº¤é‡)")
    print("   - é¥¼å›¾ (æ¿å—åˆ†å¸ƒ)")
    print("   - ä»ªè¡¨ç›˜ (å¸‚åœºæƒ…ç»ª)")
    print("   - ç»„åˆå›¾ (ä»·æ ¼-æˆäº¤é‡)")
    print("   - æ•£ç‚¹å›¾ (é£é™©-æ”¶ç›Š)")
    print("   - å¤šç§è¡¨æ ¼ (æ”¯æŒèƒŒæ™¯è‰²è§„åˆ™)")
    
    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç«¯å£
    port = 5004
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
        except ValueError:
            print("âš ï¸ æ— æ•ˆçš„ç«¯å£å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 5004")
    
    server = StackedAreaDemoServer(port=port)
    
    try:
        print("âœ… ç»¼åˆå›¾è¡¨æ¼”ç¤ºæ•°æ®åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: http://localhost:{port}")
        print("ğŸ“ˆ åŒ…å«10+ ç§å›¾è¡¨ç±»å‹å’Œæ™ºèƒ½è¡¨æ ¼å±•ç¤º")
    except Exception as e:
        print(f"âš ï¸ æ¼”ç¤ºæ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")
    
    server.run(debug=True)


if __name__ == '__main__':
    main()
